{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import xlwt\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# masterPath = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# sys.path.insert(1, os.path.join(masterPath, 'centralRepo'))\n",
    "sys.path.insert(1, '../centralRepo')\n",
    "from eegDataset import eegDataset\n",
    "from baseModel import baseModel\n",
    "from networks import *\n",
    "import transforms\n",
    "from saveData import fetchData\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['modelArguments'] = {'nChan': 22, 'nTime': 1000, 'dropoutP': 0.5,\n",
    "                                    'nBands':9, 'm' : 32, 'temporalLayer': 'LogVarLayer',\n",
    "                                    'nClass': 4, 'doWeightNorm': True}\n",
    "\n",
    "# Training related details    \n",
    "config['modelTrainArguments'] = {'stopCondi':  {'c': {'Or': {'c1': {'MaxEpoch': {'maxEpochs': 1000, 'varName' : 'epoch'}},\n",
    "                                                   'c2': {'NoDecrease': {'numEpochs' : 200, 'varName': 'valInacc'}} } }},\n",
    "      'classes': [0,1], 'sampler' : 'RandomSampler', 'loadBestModel': True,\n",
    "      'bestVarToCheck': 'valInacc', 'continueAfterEarlystop':False,'lr': 1e-3}\n",
    "\n",
    "config['batchSize'] = 16\n",
    "nGPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config['inDataPath'] = '../../data/bci42a/multiviewPython'\n",
    "# config['inLabelPath'] = '../../data//bci42a/multiviewPython/dataLabels.csv'\n",
    "# ROOT_PATH = '../../output/bci42a/ses2Test/fbcnet_cross_subs/'\n",
    "# net = FBCNet(**config['modelArguments'])\n",
    "\n",
    "config['inDataPath'] = '../../data/bci42a/rawPython'\n",
    "config['inLabelPath'] = '../../data//bci42a/rawPython/dataLabels.csv'\n",
    "ROOT_PATH = '../../output/bci42a/ses2Test/eegnet_cross_subject/'\n",
    "net = eegNet(**config['modelArguments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = eegDataset(dataPath = config['inDataPath'], dataLabelsPath= config['inLabelPath'], preloadData = False, transform= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_sub, data, model, session='1'):\n",
    "        subIdxTest = [i for i, x in enumerate(data.labels) if x[3] in test_sub and x[4] == session]\n",
    "        testData = copy.deepcopy(data)\n",
    "        testData.createPartialDataset(subIdxTest, loadNonLoadedData = True)\n",
    "\n",
    "        testResults, pred, act, pred_prob = model.test_preds(testData)\n",
    "\n",
    "        del testData\n",
    "        gc.collect()\n",
    "\n",
    "        return testResults, pred, act, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing subject 001 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.5034722222222222, 'cm': array([[24, 21, 15, 12],\n",
      "       [17, 41,  7,  7],\n",
      "       [14, 10, 40,  8],\n",
      "       [ 5, 20,  7, 40]]), 'loss': 1.4141811794704862}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.7013888888888888, 'cm': array([[47, 15,  5,  5],\n",
      "       [15, 52,  2,  3],\n",
      "       [ 2,  3, 45, 22],\n",
      "       [ 2,  4,  8, 58]]), 'loss': 0.9975721571180556}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.5659722222222222, 'cm': array([[30, 24,  9,  9],\n",
      "       [14, 51,  2,  5],\n",
      "       [11,  6, 38, 17],\n",
      "       [ 6,  9, 13, 44]]), 'loss': 1.2172532611423068}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.5416666666666666, 'cm': array([[38, 24,  6,  4],\n",
      "       [21, 39,  2, 10],\n",
      "       [ 8, 11, 37, 16],\n",
      "       [ 5, 17,  8, 42]]), 'loss': 1.2847266727023654}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.5416666666666666, 'cm': array([[28, 27, 10,  7],\n",
      "       [10, 48,  3, 11],\n",
      "       [ 8, 11, 46,  7],\n",
      "       [ 5, 18, 15, 34]]), 'loss': 1.3800603018866644}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.65625, 'cm': array([[37, 24,  5,  6],\n",
      "       [23, 45,  3,  1],\n",
      "       [11,  2, 46, 13],\n",
      "       [ 3,  0,  8, 61]]), 'loss': 0.9614543914794922}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.6458333333333334, 'cm': array([[36, 27,  5,  4],\n",
      "       [15, 49,  6,  2],\n",
      "       [ 8,  2, 43, 19],\n",
      "       [ 0,  3, 11, 58]]), 'loss': 1.0955171585083008}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.625, 'cm': array([[49, 19,  4,  0],\n",
      "       [26, 40,  3,  3],\n",
      "       [ 6,  7, 42, 17],\n",
      "       [ 1,  7, 15, 49]]), 'loss': 1.1438682344224718}\n",
      "Theoretical max accuracy: 0.9479166666666666\n",
      "Testing subject 002 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.4895833333333333, 'cm': array([[31, 18, 16,  7],\n",
      "       [ 8, 41, 15,  8],\n",
      "       [14, 14, 43,  1],\n",
      "       [15, 19, 12, 26]]), 'loss': 1.380746841430664}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.5, 'cm': array([[31, 21, 11,  9],\n",
      "       [14, 38, 10, 10],\n",
      "       [10, 19, 40,  3],\n",
      "       [10, 19,  8, 35]]), 'loss': 1.5454823176066081}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.5104166666666666, 'cm': array([[33, 14, 20,  5],\n",
      "       [18, 42,  8,  4],\n",
      "       [14,  9, 44,  5],\n",
      "       [ 8, 19, 17, 28]]), 'loss': 1.4486079745822482}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.4895833333333333, 'cm': array([[34, 25, 11,  2],\n",
      "       [17, 37, 12,  6],\n",
      "       [14, 15, 41,  2],\n",
      "       [10, 18, 15, 29]]), 'loss': 1.6085451973809137}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.5277777777777778, 'cm': array([[31, 18, 14,  9],\n",
      "       [ 8, 42, 14,  8],\n",
      "       [11, 17, 43,  1],\n",
      "       [11, 15, 10, 36]]), 'loss': 1.3118529849582248}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.4791666666666667, 'cm': array([[29, 20, 16,  7],\n",
      "       [20, 32, 13,  7],\n",
      "       [ 9, 10, 49,  4],\n",
      "       [15, 16, 13, 28]]), 'loss': 1.5870674981011286}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.4895833333333333, 'cm': array([[34, 23,  8,  7],\n",
      "       [22, 34, 10,  6],\n",
      "       [19, 12, 37,  4],\n",
      "       [11, 17,  8, 36]]), 'loss': 1.4669240315755208}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.4756944444444444, 'cm': array([[27, 23,  6, 16],\n",
      "       [17, 41,  7,  7],\n",
      "       [ 7, 19, 38,  8],\n",
      "       [12, 13, 16, 31]]), 'loss': 1.5588834550645616}\n",
      "Theoretical max accuracy: 0.8819444444444444\n",
      "Testing subject 003 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.7986111111111112, 'cm': array([[49, 14,  7,  2],\n",
      "       [ 1, 63,  7,  1],\n",
      "       [ 0, 10, 60,  2],\n",
      "       [ 1,  4,  9, 58]]), 'loss': 0.6582983864678277}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.6215277777777778, 'cm': array([[35, 15, 17,  5],\n",
      "       [13, 47, 11,  1],\n",
      "       [ 9,  9, 54,  0],\n",
      "       [ 7, 18,  4, 43]]), 'loss': 1.220675786336263}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.6944444444444444, 'cm': array([[44, 10, 12,  6],\n",
      "       [11, 46,  4, 11],\n",
      "       [11, 11, 50,  0],\n",
      "       [ 4,  5,  3, 60]]), 'loss': 0.9359094831678603}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.6284722222222222, 'cm': array([[39, 13, 12,  8],\n",
      "       [19, 39,  7,  7],\n",
      "       [ 5,  6, 61,  0],\n",
      "       [ 4, 18,  8, 42]]), 'loss': 1.00994873046875}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.6215277777777778, 'cm': array([[37, 16, 11,  8],\n",
      "       [12, 51,  4,  5],\n",
      "       [ 9,  6, 56,  1],\n",
      "       [ 8, 22,  7, 35]]), 'loss': 1.06769773695204}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.6701388888888888, 'cm': array([[37, 20, 12,  3],\n",
      "       [ 9, 47, 12,  4],\n",
      "       [ 6,  9, 55,  2],\n",
      "       [ 3, 10,  5, 54]]), 'loss': 0.9583453072441949}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.6805555555555556, 'cm': array([[38, 15, 13,  6],\n",
      "       [ 6, 47, 15,  4],\n",
      "       [ 4,  7, 61,  0],\n",
      "       [ 3, 12,  7, 50]]), 'loss': 0.8248392211066352}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.7152777777777778, 'cm': array([[50, 11,  6,  5],\n",
      "       [13, 45, 11,  3],\n",
      "       [ 1,  7, 59,  5],\n",
      "       [ 3,  5, 12, 52]]), 'loss': 1.0017035802205403}\n",
      "Theoretical max accuracy: 0.9652777777777778\n",
      "Testing subject 004 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.5277777777777778, 'cm': array([[49,  7, 11,  5],\n",
      "       [13, 31, 16, 12],\n",
      "       [10, 12, 42,  8],\n",
      "       [13, 14, 15, 30]]), 'loss': 1.303060319688585}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.5590277777777778, 'cm': array([[42, 14,  9,  7],\n",
      "       [14, 37, 11, 10],\n",
      "       [12, 11, 44,  5],\n",
      "       [14, 12,  8, 38]]), 'loss': 1.3374705844455295}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.5451388888888888, 'cm': array([[46, 11,  8,  7],\n",
      "       [11, 43,  7, 11],\n",
      "       [11, 15, 35, 11],\n",
      "       [ 7, 18, 14, 33]]), 'loss': 1.3703818851047092}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.5069444444444444, 'cm': array([[41, 14,  9,  8],\n",
      "       [11, 34,  6, 21],\n",
      "       [10, 11, 37, 14],\n",
      "       [ 8, 15, 15, 34]]), 'loss': 1.4205457899305556}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.4826388888888889, 'cm': array([[40, 14, 12,  6],\n",
      "       [18, 30, 16,  8],\n",
      "       [ 9, 17, 38,  8],\n",
      "       [15, 12, 14, 31]]), 'loss': 1.4800874922010634}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.5694444444444444, 'cm': array([[43, 13, 12,  4],\n",
      "       [19, 28, 15, 10],\n",
      "       [ 2,  9, 50, 11],\n",
      "       [10,  9, 10, 43]]), 'loss': 1.279698583814833}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.5833333333333334, 'cm': array([[54,  6,  8,  4],\n",
      "       [22, 30,  9, 11],\n",
      "       [ 4, 11, 42, 15],\n",
      "       [ 5, 11, 14, 42]]), 'loss': 1.2231838438245985}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.5034722222222222, 'cm': array([[49, 13,  6,  4],\n",
      "       [26, 32,  6,  8],\n",
      "       [15, 15, 26, 16],\n",
      "       [ 9, 16,  9, 38]]), 'loss': 1.3525496588812933}\n",
      "Theoretical max accuracy: 0.9097222222222222\n",
      "Testing subject 005 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.59375, 'cm': array([[44,  9,  6, 13],\n",
      "       [ 8, 47,  5, 12],\n",
      "       [ 5, 19, 34, 14],\n",
      "       [ 6, 13,  7, 46]]), 'loss': 1.2353253894382052}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.6041666666666666, 'cm': array([[50,  3,  4, 15],\n",
      "       [ 2, 49,  4, 17],\n",
      "       [17, 11, 29, 15],\n",
      "       [ 4, 16,  6, 46]]), 'loss': 1.3336730533175998}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.6041666666666666, 'cm': array([[44, 12,  4, 12],\n",
      "       [11, 48,  5,  8],\n",
      "       [16, 11, 36,  9],\n",
      "       [11, 12,  3, 46]]), 'loss': 1.2934208975897894}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.6805555555555556, 'cm': array([[46,  3,  9, 14],\n",
      "       [ 0, 57,  3, 12],\n",
      "       [11, 11, 38, 12],\n",
      "       [ 3,  8,  6, 55]]), 'loss': 1.1321081585354276}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.5868055555555556, 'cm': array([[49,  8,  4, 11],\n",
      "       [ 7, 47,  7, 11],\n",
      "       [11, 16, 34, 11],\n",
      "       [17, 10,  6, 39]]), 'loss': 1.2501712375217013}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.6805555555555556, 'cm': array([[56,  2,  4, 10],\n",
      "       [ 2, 53,  4, 13],\n",
      "       [14,  5, 39, 14],\n",
      "       [ 6, 14,  4, 48]]), 'loss': 0.9961217244466146}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.6041666666666666, 'cm': array([[56,  3,  2, 11],\n",
      "       [ 0, 45,  5, 22],\n",
      "       [ 7,  7, 29, 29],\n",
      "       [ 6, 19,  3, 44]]), 'loss': 1.1461400985717773}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.6180555555555556, 'cm': array([[47,  2,  8, 15],\n",
      "       [ 4, 51,  6, 11],\n",
      "       [14, 13, 36,  9],\n",
      "       [ 5, 19,  4, 44]]), 'loss': 1.2344872156778972}\n",
      "Theoretical max accuracy: 0.96875\n",
      "Testing subject 006 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.5243055555555556, 'cm': array([[45, 11,  5, 11],\n",
      "       [15, 34,  6, 17],\n",
      "       [ 7, 21, 35,  9],\n",
      "       [13, 18,  4, 37]]), 'loss': 1.9302130805121527}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.4722222222222222, 'cm': array([[33, 12, 10, 17],\n",
      "       [15, 38,  8, 11],\n",
      "       [17, 17, 30,  8],\n",
      "       [16, 15,  6, 35]]), 'loss': 1.622422218322754}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.4756944444444444, 'cm': array([[45, 14,  6,  7],\n",
      "       [15, 43,  6,  8],\n",
      "       [16, 23, 29,  4],\n",
      "       [24, 25,  3, 20]]), 'loss': 1.639679167005751}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.5034722222222222, 'cm': array([[36, 11, 10, 15],\n",
      "       [ 9, 40,  6, 17],\n",
      "       [ 8, 18, 29, 17],\n",
      "       [12, 13,  7, 40]]), 'loss': 1.7111695607503254}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.4965277777777778, 'cm': array([[37, 14,  6, 15],\n",
      "       [14, 37,  7, 14],\n",
      "       [ 9, 17, 37,  9],\n",
      "       [19, 13,  8, 32]]), 'loss': 1.5545550452338324}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.4791666666666667, 'cm': array([[24, 19, 11, 18],\n",
      "       [ 7, 45,  8, 12],\n",
      "       [ 8, 25, 31,  8],\n",
      "       [10, 19,  5, 38]]), 'loss': 1.6129588021172419}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.5243055555555556, 'cm': array([[38, 10,  8, 16],\n",
      "       [ 8, 40, 10, 14],\n",
      "       [10, 15, 39,  8],\n",
      "       [15, 14,  9, 34]]), 'loss': 1.5263379414876301}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.4583333333333333, 'cm': array([[37,  9, 10, 16],\n",
      "       [17, 37,  9,  9],\n",
      "       [15, 10, 32, 15],\n",
      "       [13, 27,  6, 26]]), 'loss': 1.781028111775716}\n",
      "Theoretical max accuracy: 0.9305555555555556\n",
      "Testing subject 007 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.625, 'cm': array([[35,  4, 21, 12],\n",
      "       [ 8, 32, 10, 22],\n",
      "       [ 4,  4, 50, 14],\n",
      "       [ 2,  4,  3, 63]]), 'loss': 1.4760745366414387}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.6354166666666666, 'cm': array([[41,  2, 18, 11],\n",
      "       [ 6, 43,  7, 16],\n",
      "       [11,  6, 48,  7],\n",
      "       [ 4, 15,  2, 51]]), 'loss': 1.068736606174045}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.6423611111111112, 'cm': array([[35,  8, 18, 11],\n",
      "       [11, 29,  8, 24],\n",
      "       [ 4,  1, 52, 15],\n",
      "       [ 1,  1,  1, 69]]), 'loss': 1.2126033571031358}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.6284722222222222, 'cm': array([[41,  5, 17,  9],\n",
      "       [ 3, 42,  5, 22],\n",
      "       [ 9,  8, 38, 17],\n",
      "       [ 2,  8,  2, 60]]), 'loss': 1.217490832010905}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.6354166666666666, 'cm': array([[41,  8, 16,  7],\n",
      "       [ 4, 46, 12, 10],\n",
      "       [ 3, 14, 49,  6],\n",
      "       [ 5, 12,  8, 47]]), 'loss': 1.4590337541368272}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.6284722222222222, 'cm': array([[34,  9, 18, 11],\n",
      "       [ 4, 51,  7, 10],\n",
      "       [ 6, 10, 48,  8],\n",
      "       [10, 10,  4, 48]]), 'loss': 1.1879001193576388}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.6770833333333334, 'cm': array([[33,  2, 17, 20],\n",
      "       [ 1, 46, 10, 15],\n",
      "       [ 1, 11, 52,  8],\n",
      "       [ 1,  4,  3, 64]]), 'loss': 1.2002372741699219}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.6111111111111112, 'cm': array([[35, 11, 17,  9],\n",
      "       [ 8, 37,  7, 20],\n",
      "       [ 2, 13, 44, 13],\n",
      "       [ 6,  4,  2, 60]]), 'loss': 1.203283839755588}\n",
      "Theoretical max accuracy: 0.9548611111111112\n",
      "Testing subject 008 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.6736111111111112, 'cm': array([[52,  1, 17,  2],\n",
      "       [ 4, 49, 15,  4],\n",
      "       [ 8,  8, 51,  5],\n",
      "       [ 7,  3, 20, 42]]), 'loss': 1.093738979763455}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.5625, 'cm': array([[42,  7, 13, 10],\n",
      "       [10, 30, 17, 15],\n",
      "       [ 6,  5, 56,  5],\n",
      "       [ 5, 14, 19, 34]]), 'loss': 1.3624660703870985}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.5833333333333334, 'cm': array([[46,  7, 16,  3],\n",
      "       [12, 34, 14, 12],\n",
      "       [12,  9, 47,  4],\n",
      "       [15,  8,  8, 41]]), 'loss': 1.1805481380886502}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.6076388888888888, 'cm': array([[48,  4, 18,  2],\n",
      "       [15, 39, 13,  5],\n",
      "       [12,  7, 51,  2],\n",
      "       [10, 12, 13, 37]]), 'loss': 1.0832570393880208}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.5520833333333334, 'cm': array([[35,  8, 15, 14],\n",
      "       [10, 39, 13, 10],\n",
      "       [ 6,  7, 52,  7],\n",
      "       [10,  9, 20, 33]]), 'loss': 1.4549649556477864}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.5277777777777778, 'cm': array([[35,  8, 18, 11],\n",
      "       [10, 38, 12, 12],\n",
      "       [ 6,  9, 47, 10],\n",
      "       [11,  8, 21, 32]]), 'loss': 1.4868119557698567}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.6527777777777778, 'cm': array([[49,  5, 15,  3],\n",
      "       [ 9, 52,  7,  4],\n",
      "       [ 9, 15, 44,  4],\n",
      "       [ 4, 13, 12, 43]]), 'loss': 1.198841518825955}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.6805555555555556, 'cm': array([[49,  2, 17,  4],\n",
      "       [ 6, 47, 15,  4],\n",
      "       [ 6,  6, 50, 10],\n",
      "       [ 5,  4, 13, 50]]), 'loss': 0.9691172705756294}\n",
      "Theoretical max accuracy: 0.9444444444444444\n",
      "Testing subject 009 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.5659722222222222, 'cm': array([[57, 10,  4,  1],\n",
      "       [ 3, 34, 24, 11],\n",
      "       [10,  6, 31, 25],\n",
      "       [ 3,  3, 25, 41]]), 'loss': 1.5996242099338107}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.4652777777777778, 'cm': array([[31, 22, 14,  5],\n",
      "       [ 6, 46, 16,  4],\n",
      "       [12, 18, 34,  8],\n",
      "       [19, 14, 16, 23]]), 'loss': 1.7695213953653972}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.6319444444444444, 'cm': array([[58, 11,  2,  1],\n",
      "       [ 6, 47, 16,  3],\n",
      "       [ 5, 21, 32, 14],\n",
      "       [ 3,  5, 19, 45]]), 'loss': 1.2124682532416449}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.5763888888888888, 'cm': array([[50, 17,  3,  2],\n",
      "       [ 4, 40, 18, 10],\n",
      "       [10, 14, 30, 18],\n",
      "       [ 6,  7, 13, 46]]), 'loss': 1.3629199133978949}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.4791666666666667, 'cm': array([[40, 15,  7, 10],\n",
      "       [14, 38, 17,  3],\n",
      "       [12, 10, 28, 22],\n",
      "       [19, 10, 11, 32]]), 'loss': 1.7808407677544489}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.4861111111111111, 'cm': array([[36, 13, 17,  6],\n",
      "       [ 8, 41, 17,  6],\n",
      "       [13, 12, 30, 17],\n",
      "       [12, 14, 13, 33]]), 'loss': 1.7944051954481337}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.5798611111111112, 'cm': array([[51, 10,  8,  3],\n",
      "       [ 5, 44, 16,  7],\n",
      "       [10, 11, 31, 20],\n",
      "       [10,  9, 12, 41]]), 'loss': 1.3259551790025499}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.6597222222222222, 'cm': array([[51, 10,  5,  6],\n",
      "       [ 4, 41, 13, 14],\n",
      "       [11, 10, 36, 15],\n",
      "       [ 3,  3,  4, 62]]), 'loss': 1.2813310623168945}\n",
      "Theoretical max accuracy: 0.9513888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    }
   ],
   "source": [
    "subs = list(range(9))\n",
    "accs = []\n",
    "all_preds = {}\n",
    "all_pred_probs = {}\n",
    "all_losses = {}\n",
    "all_test_results = {}\n",
    "all_acts = {}\n",
    "all_train_preds = {}\n",
    "all_train_pred_probs = {}\n",
    "all_train_losses = {}\n",
    "all_train_results = {}\n",
    "for test_sub in subs:\n",
    "    test_sub_str = '00' + str(test_sub + 1)\n",
    "    preds = []\n",
    "    pred_probs = []\n",
    "    train_preds = []\n",
    "    train_pred_probs = []\n",
    "    results = {}\n",
    "    train_results = {}\n",
    "    train_losses = []\n",
    "    print(\"Testing subject \" + test_sub_str + \" with all models...\")\n",
    "    for sub in subs:\n",
    "        if(sub == test_sub):\n",
    "            continue\n",
    "#             state_dict_path = os.path.join(ROOT_PATH, 'sub' + str(sub), 'network_state_dict.pth'\n",
    "        else:\n",
    "            state_dict_path = os.path.join(ROOT_PATH, 'sub' + str(sub), 'finetuned_sub' + str(test_sub), 'network_state_dict.pth')\n",
    "    #     print(state_dict_path)\n",
    "        netInitState = torch.load(state_dict_path)\n",
    "        net.load_state_dict(netInitState, strict=False)\n",
    "        outPathSub = None\n",
    "        model = baseModel(net=net, resultsSavePath=outPathSub, batchSize= config['batchSize'], nGPU = nGPU)\n",
    "        testResults, pred, act, pred_prob = test_model(test_sub_str, data, model, session='0')\n",
    "        train_preds.append(pred)\n",
    "        train_pred_probs.append(pred_prob)\n",
    "        train_results[sub] = testResults\n",
    "        train_losses.append(testResults['loss'])\n",
    "        \n",
    "        testResults, pred, act, pred_prob = test_model(test_sub_str, data, model)\n",
    "        preds.append(pred)\n",
    "        pred_probs.append(pred_prob)\n",
    "        results[sub] = testResults\n",
    "        print(\"Results for model\", sub, testResults)\n",
    "    \n",
    "    correct = 0\n",
    "    for i in range(len(act)):\n",
    "        for pred in preds:\n",
    "            if(pred[i] == act[i]):\n",
    "                correct += 1\n",
    "                break\n",
    "    \n",
    "    all_preds[test_sub] = preds\n",
    "    all_pred_probs[test_sub] = pred_probs\n",
    "    all_acts[test_sub] = act\n",
    "    all_test_results[test_sub] = results\n",
    "    \n",
    "    all_train_preds[test_sub] = train_preds\n",
    "    all_train_pred_probs[test_sub] = train_pred_probs\n",
    "    all_train_losses[test_sub] = train_losses\n",
    "    all_train_results[test_sub] = train_results\n",
    "    \n",
    "    acc = correct/len(act)\n",
    "    accs.append(acc)\n",
    "    print(\"Theoretical max accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9479166666666666,\n",
       " 0.8819444444444444,\n",
       " 0.9652777777777778,\n",
       " 0.9097222222222222,\n",
       " 0.96875,\n",
       " 0.9305555555555556,\n",
       " 0.9548611111111112,\n",
       " 0.9444444444444444,\n",
       " 0.9513888888888888]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average theoretical max accuracy: 0.939429012345679\n"
     ]
    }
   ],
   "source": [
    "avg_acc = sum(accs) / len(accs)\n",
    "print(\"Average theoretical max accuracy:\", avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.792 & 88.194 & 96.528 & 90.972 & 96.875 & 93.056 & 95.486 & 94.444 & 95.139 & 93.943\n"
     ]
    }
   ],
   "source": [
    "accs.append(avg_acc)\n",
    "tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_spec_accs = [all_test_results[i][i]['acc'] for i in range(9)]\n",
    "# print(sub_spec_accs)\n",
    "# print(\"Subject specific average accuracy:\", sum(sub_spec_accs) / len(sub_spec_accs))\n",
    "# print(\"Subject specific median accuracy:\", statistics.median(sub_spec_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voted accuracy: 0.7083333333333334\n",
      "Voted accuracy: 0.5659722222222222\n",
      "Voted accuracy: 0.7708333333333334\n",
      "Voted accuracy: 0.6423611111111112\n",
      "Voted accuracy: 0.7048611111111112\n",
      "Voted accuracy: 0.5798611111111112\n",
      "Voted accuracy: 0.7361111111111112\n",
      "Voted accuracy: 0.7083333333333334\n",
      "Voted accuracy: 0.6736111111111112\n",
      "Average voted accuracy: 0.6766975308641976\n",
      "Median voted accuracy: 0.7048611111111112\n",
      "70.833 & 56.597 & 77.083 & 64.236 & 70.486 & 57.986 & 73.611 & 70.833 & 67.361 & 67.670\n"
     ]
    }
   ],
   "source": [
    "voted_accs = []\n",
    "for test_sub in subs:\n",
    "    voted_pred = []\n",
    "#     test_sub = 1\n",
    "    preds = all_preds[test_sub]\n",
    "    act = all_acts[test_sub]\n",
    "    for i in range(len(preds[0])):\n",
    "        votes = {l:0 for l in range(4)}\n",
    "        for pred in preds:\n",
    "            votes[pred[i]]+=1\n",
    "        voted_pred.append(max(votes, key=votes.get))\n",
    "\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(voted_pred, act):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(act)\n",
    "    voted_accs.append(voted_acc)\n",
    "    print(\"Voted accuracy:\", voted_acc)\n",
    "    \n",
    "avg_voted_acc = sum(voted_accs) / len(voted_accs)\n",
    "print(\"Average voted accuracy:\", avg_voted_acc)\n",
    "print(\"Median voted accuracy:\", statistics.median(voted_accs))\n",
    "voted_accs.append(avg_voted_acc)\n",
    "tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in voted_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft probability combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft probability combined accuracy: 0.7743055555555556\n",
      "Soft probability combined accuracy: 0.5694444444444444\n",
      "Soft probability combined accuracy: 0.8125\n",
      "Soft probability combined accuracy: 0.65625\n",
      "Soft probability combined accuracy: 0.7395833333333334\n",
      "Soft probability combined accuracy: 0.6180555555555556\n",
      "Soft probability combined accuracy: 0.7430555555555556\n",
      "Soft probability combined accuracy: 0.7256944444444444\n",
      "Soft probability combined accuracy: 0.6701388888888888\n",
      "Average combined accuracy: 0.7010030864197532\n",
      "Median combined accuracy: 0.7256944444444444\n",
      "77.431 & 56.944 & 81.250 & 65.625 & 73.958 & 61.806 & 74.306 & 72.569 & 67.014 & 70.100\n"
     ]
    }
   ],
   "source": [
    "comb_accs = []\n",
    "for test_sub in subs:\n",
    "    pred_probs = np.array(all_pred_probs[test_sub])\n",
    "    n, h, w, c = pred_probs.shape\n",
    "    pred_probs = np.reshape(pred_probs, (n, h*w, c))\n",
    "    class_probs = np.sum(pred_probs, axis=0)\n",
    "    soft_preds = np.argmax(class_probs, axis=1)\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(soft_preds, all_acts[test_sub]):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(all_acts[test_sub])\n",
    "    comb_accs.append(voted_acc)\n",
    "    print(\"Soft probability combined accuracy:\", voted_acc)\n",
    "\n",
    "avg_comb_acc = sum(comb_accs) / len(comb_accs)\n",
    "print(\"Average combined accuracy:\", avg_comb_acc)\n",
    "print(\"Median combined accuracy:\", statistics.median(comb_accs))\n",
    "comb_accs.append(avg_comb_acc)\n",
    "tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in comb_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {test_sub: {train_sub: results['cm'] for train_sub, results in test_results.items()} for test_sub, test_results in all_train_results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {test_sub: {train_sub: np.array([cm[i][i]/np.sum(cm[i,:]) for i in range(4)]) for train_sub, cm in test_results.items()} for test_sub, test_results in cms.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_sums = {test_sub: np.array([np.sum(recalls) for train_sub, recalls in test_results.items()]) for test_sub, test_results in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.94444444, 4.        , 3.94444444, 3.86111111, 3.94444444,\n",
       "       3.97222222, 3.97222222, 3.93055556])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_sums[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7, 0, 2, 4, 5, 6, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(recall_sums[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft probability combined accuracy: 0.7777777777777778\n",
      "Soft probability combined accuracy: 0.5729166666666666\n",
      "Soft probability combined accuracy: 0.8125\n",
      "Soft probability combined accuracy: 0.65625\n",
      "Soft probability combined accuracy: 0.7361111111111112\n",
      "Soft probability combined accuracy: 0.6180555555555556\n",
      "Soft probability combined accuracy: 0.7430555555555556\n",
      "Soft probability combined accuracy: 0.7256944444444444\n",
      "Soft probability combined accuracy: 0.6701388888888888\n",
      "Average combined accuracy: 0.7013888888888888\n",
      "Median combined accuracy: 0.7256944444444444\n",
      "77.778 & 57.292 & 81.250 & 65.625 & 73.611 & 61.806 & 74.306 & 72.569 & 67.014 & 70.139\n"
     ]
    }
   ],
   "source": [
    "comb_accs = []\n",
    "for test_sub in subs:\n",
    "    mlist = list(range(9))\n",
    "    mlist.pop(test_sub)\n",
    "    pred_probs = np.array(all_pred_probs[test_sub])\n",
    "    n, h, w, c = pred_probs.shape\n",
    "    pred_probs = np.reshape(pred_probs, (n, h*w, c))\n",
    "#     print(pred_probs)\n",
    "    for i in range(len(pred_probs)):\n",
    "#         print(pred_probs[i])\n",
    "        for j in range(len(pred_probs[i])):\n",
    "            pred_probs[i][j] = np.multiply(pred_probs[i][j], metrics[test_sub][mlist[i]])\n",
    "    class_probs = np.sum(pred_probs, axis=0)\n",
    "    soft_preds = np.argmax(class_probs, axis=1)\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(soft_preds, all_acts[test_sub]):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(all_acts[test_sub])\n",
    "    comb_accs.append(voted_acc)\n",
    "    print(\"Soft probability combined accuracy:\", voted_acc)\n",
    "\n",
    "avg_comb_acc = sum(comb_accs) / len(comb_accs)\n",
    "print(\"Average combined accuracy:\", avg_comb_acc)\n",
    "print(\"Median combined accuracy:\", statistics.median(comb_accs))\n",
    "comb_accs.append(avg_comb_acc)\n",
    "tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in comb_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voted accuracy: 0.7048611111111112\n",
      "Voted accuracy: 0.5729166666666666\n",
      "Voted accuracy: 0.7708333333333334\n",
      "Voted accuracy: 0.6458333333333334\n",
      "Voted accuracy: 0.7048611111111112\n",
      "Voted accuracy: 0.59375\n",
      "Voted accuracy: 0.7291666666666666\n",
      "Voted accuracy: 0.7048611111111112\n",
      "Voted accuracy: 0.6805555555555556\n",
      "Average voted accuracy: 0.6786265432098766\n",
      "Median voted accuracy: 0.7048611111111112\n",
      "70.486 & 57.292 & 77.083 & 64.583 & 70.486 & 59.375 & 72.917 & 70.486 & 68.056 & 67.863\n"
     ]
    }
   ],
   "source": [
    "voted_accs = []\n",
    "for test_sub in subs:\n",
    "    voted_pred = []\n",
    "    mlist = list(range(9))\n",
    "    mlist.pop(test_sub)\n",
    "#     test_sub = 1\n",
    "    preds = all_preds[test_sub]\n",
    "    act = all_acts[test_sub]\n",
    "    for i in range(len(preds[0])):\n",
    "        votes = {l:0 for l in range(4)}\n",
    "        for j, pred in enumerate(preds):\n",
    "            votes[pred[i]]+=metrics[test_sub][mlist[j]][pred[i]]\n",
    "        voted_pred.append(max(votes, key=votes.get))\n",
    "\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(voted_pred, act):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(act)\n",
    "    voted_accs.append(voted_acc)\n",
    "    print(\"Voted accuracy:\", voted_acc)\n",
    "    \n",
    "avg_voted_acc = sum(voted_accs) / len(voted_accs)\n",
    "print(\"Average voted accuracy:\", avg_voted_acc)\n",
    "print(\"Median voted accuracy:\", statistics.median(voted_accs))\n",
    "voted_accs.append(avg_voted_acc)\n",
    "tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in voted_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recall scaled soft probability combined accuracy: 0.7256944444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.5833333333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.8090277777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.6145833333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.7326388888888888\n",
      "Top recall scaled soft probability combined accuracy: 0.5763888888888888\n",
      "Top recall scaled soft probability combined accuracy: 0.7361111111111112\n",
      "Top recall scaled soft probability combined accuracy: 0.7083333333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.6458333333333334\n",
      "Average combined accuracy: 0.681327160493827\n",
      "Median combined accuracy: 0.7083333333333334\n",
      "72.569 & 58.333 & 80.903 & 61.458 & 73.264 & 57.639 & 73.611 & 70.833 & 64.583 & 68.133\n"
     ]
    }
   ],
   "source": [
    "comb_accs = []\n",
    "for test_sub in subs:\n",
    "    mlist = list(range(9))\n",
    "    mlist.pop(test_sub)\n",
    "    sorted_recall_idx = np.argsort(recall_sums[test_sub])\n",
    "    # print(sorted_recall_idx)\n",
    "    # print(sorted_recall_idx[-5:])\n",
    "    pred_probs = np.array(all_pred_probs[test_sub])\n",
    "    n, h, w, c = pred_probs.shape\n",
    "    pred_probs = np.reshape(pred_probs, (n, h*w, c))\n",
    "#     print(pred_probs.shape)\n",
    "    pred_probs = np.take(pred_probs, sorted_recall_idx[-3:], 0)\n",
    "#     print(pred_probs.shape)\n",
    "    for i in range(len(pred_probs)):\n",
    "        for j in range(len(pred_probs[i])):\n",
    "            pred_probs[i][j] = np.multiply(pred_probs[i][j], metrics[test_sub][mlist[i]])\n",
    "    class_probs = np.sum(pred_probs, axis=0)\n",
    "    soft_preds = np.argmax(class_probs, axis=1)\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(soft_preds, all_acts[test_sub]):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(all_acts[test_sub])\n",
    "    comb_accs.append(voted_acc)\n",
    "    print(\"Top recall scaled soft probability combined accuracy:\", voted_acc)\n",
    "    \n",
    "avg_comb_acc = sum(comb_accs) / len(comb_accs)\n",
    "print(\"Average combined accuracy:\", avg_comb_acc)\n",
    "print(\"Median combined accuracy:\", statistics.median(comb_accs))\n",
    "comb_accs.append(avg_comb_acc)\n",
    "tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in comb_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-2\n",
      "Top recall scaled soft probability combined accuracy: 0.7465277777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.5138888888888888\n",
      "Top recall scaled soft probability combined accuracy: 0.8125\n",
      "Top recall scaled soft probability combined accuracy: 0.65625\n",
      "Top recall scaled soft probability combined accuracy: 0.7152777777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.5902777777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.7638888888888888\n",
      "Top recall scaled soft probability combined accuracy: 0.7083333333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.6215277777777778\n",
      "Average combined accuracy: 0.6809413580246912\n",
      "Median combined accuracy: 0.7083333333333334\n",
      "74.653 & 51.389 & 81.250 & 65.625 & 71.528 & 59.028 & 76.389 & 70.833 & 62.153 & 68.094\n",
      "\n",
      "\n",
      "Top-3\n",
      "Top recall scaled soft probability combined accuracy: 0.7256944444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.5868055555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.7152777777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.65625\n",
      "Top recall scaled soft probability combined accuracy: 0.7118055555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.6041666666666666\n",
      "Top recall scaled soft probability combined accuracy: 0.7638888888888888\n",
      "Top recall scaled soft probability combined accuracy: 0.7222222222222222\n",
      "Top recall scaled soft probability combined accuracy: 0.6458333333333334\n",
      "Average combined accuracy: 0.6813271604938271\n",
      "Median combined accuracy: 0.7118055555555556\n",
      "72.569 & 58.681 & 71.528 & 65.625 & 71.181 & 60.417 & 76.389 & 72.222 & 64.583 & 68.133\n",
      "\n",
      "\n",
      "Top-4\n",
      "Top recall scaled soft probability combined accuracy: 0.75\n",
      "Top recall scaled soft probability combined accuracy: 0.5833333333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.7465277777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.4861111111111111\n",
      "Top recall scaled soft probability combined accuracy: 0.7361111111111112\n",
      "Top recall scaled soft probability combined accuracy: 0.6215277777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.7569444444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.6944444444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.6805555555555556\n",
      "Average combined accuracy: 0.6728395061728395\n",
      "Median combined accuracy: 0.6944444444444444\n",
      "75.000 & 58.333 & 74.653 & 48.611 & 73.611 & 62.153 & 75.694 & 69.444 & 68.056 & 67.284\n",
      "\n",
      "\n",
      "Top-5\n",
      "Top recall scaled soft probability combined accuracy: 0.7777777777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.59375\n",
      "Top recall scaled soft probability combined accuracy: 0.8090277777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.5868055555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.6805555555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.6180555555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.75\n",
      "Top recall scaled soft probability combined accuracy: 0.7048611111111112\n",
      "Top recall scaled soft probability combined accuracy: 0.6909722222222222\n",
      "Average combined accuracy: 0.6902006172839505\n",
      "Median combined accuracy: 0.6909722222222222\n",
      "77.778 & 59.375 & 80.903 & 58.681 & 68.056 & 61.806 & 75.000 & 70.486 & 69.097 & 69.020\n",
      "\n",
      "\n",
      "Top-6\n",
      "Top recall scaled soft probability combined accuracy: 0.78125\n",
      "Top recall scaled soft probability combined accuracy: 0.6111111111111112\n",
      "Top recall scaled soft probability combined accuracy: 0.8090277777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.6145833333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.7152777777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.5034722222222222\n",
      "Top recall scaled soft probability combined accuracy: 0.7430555555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.7083333333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.6944444444444444\n",
      "Average combined accuracy: 0.6867283950617283\n",
      "Median combined accuracy: 0.7083333333333334\n",
      "78.125 & 61.111 & 80.903 & 61.458 & 71.528 & 50.347 & 74.306 & 70.833 & 69.444 & 68.673\n",
      "\n",
      "\n",
      "Top-7\n",
      "Top recall scaled soft probability combined accuracy: 0.78125\n",
      "Top recall scaled soft probability combined accuracy: 0.5868055555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.8194444444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.6215277777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.7326388888888888\n",
      "Top recall scaled soft probability combined accuracy: 0.5277777777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.6770833333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.7256944444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.6631944444444444\n",
      "Average combined accuracy: 0.681712962962963\n",
      "Median combined accuracy: 0.6770833333333334\n",
      "78.125 & 58.681 & 81.944 & 62.153 & 73.264 & 52.778 & 67.708 & 72.569 & 66.319 & 68.171\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,8):\n",
    "    comb_accs = []\n",
    "    print(\"Top-\" + str(i))\n",
    "    for test_sub in subs:\n",
    "        mlist = list(range(9))\n",
    "        mlist.pop(test_sub)\n",
    "        sorted_recall_idx = np.argsort(recall_sums[test_sub])\n",
    "        # print(sorted_recall_idx)\n",
    "        # print(sorted_recall_idx[-5:])\n",
    "        pred_probs = np.array(all_pred_probs[test_sub])\n",
    "        n, h, w, c = pred_probs.shape\n",
    "        pred_probs = np.reshape(pred_probs, (n, h*w, c))\n",
    "    #     print(pred_probs.shape)\n",
    "        pred_probs = np.take(pred_probs, sorted_recall_idx[-i:], 0)\n",
    "    #     print(pred_probs.shape)\n",
    "        for i in range(len(pred_probs)):\n",
    "            for j in range(len(pred_probs[i])):\n",
    "                pred_probs[i][j] = np.multiply(pred_probs[i][j], metrics[test_sub][mlist[i]])\n",
    "        class_probs = np.sum(pred_probs, axis=0)\n",
    "        soft_preds = np.argmax(class_probs, axis=1)\n",
    "        correct = 0\n",
    "        for pred, act_val in zip(soft_preds, all_acts[test_sub]):\n",
    "            if(pred == act_val):\n",
    "                correct += 1\n",
    "        voted_acc = correct / len(all_acts[test_sub])\n",
    "        comb_accs.append(voted_acc)\n",
    "        print(\"Top recall scaled soft probability combined accuracy:\", voted_acc)\n",
    "\n",
    "    avg_comb_acc = sum(comb_accs) / len(comb_accs)\n",
    "    print(\"Average combined accuracy:\", avg_comb_acc)\n",
    "    print(\"Median combined accuracy:\", statistics.median(comb_accs))\n",
    "    comb_accs.append(avg_comb_acc)\n",
    "    tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in comb_accs])\n",
    "    print(tabstr)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
