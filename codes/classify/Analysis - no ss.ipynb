{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import xlwt\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# masterPath = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# sys.path.insert(1, os.path.join(masterPath, 'centralRepo'))\n",
    "sys.path.insert(1, '../centralRepo')\n",
    "from eegDataset import eegDataset\n",
    "from baseModel import baseModel\n",
    "from networks import *\n",
    "import transforms\n",
    "from saveData import fetchData\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['modelArguments'] = {'nChan': 22, 'nTime': 1000, 'dropoutP': 0.5,\n",
    "                                    'nBands':9, 'm' : 32, 'temporalLayer': 'LogVarLayer',\n",
    "                                    'nClass': 4, 'doWeightNorm': True}\n",
    "\n",
    "# Training related details    \n",
    "config['modelTrainArguments'] = {'stopCondi':  {'c': {'Or': {'c1': {'MaxEpoch': {'maxEpochs': 1000, 'varName' : 'epoch'}},\n",
    "                                                   'c2': {'NoDecrease': {'numEpochs' : 200, 'varName': 'valInacc'}} } }},\n",
    "      'classes': [0,1], 'sampler' : 'RandomSampler', 'loadBestModel': True,\n",
    "      'bestVarToCheck': 'valInacc', 'continueAfterEarlystop':False,'lr': 1e-3}\n",
    "\n",
    "config['batchSize'] = 16\n",
    "nGPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['inDataPath'] = '../../data/bci42a/multiviewPython'\n",
    "config['inLabelPath'] = '../../data//bci42a/multiviewPython/dataLabels.csv'\n",
    "ROOT_PATH = '../../output/bci42a/ses2Test/fbcnet_cross_subs/'\n",
    "net = FBCNet(**config['modelArguments'])\n",
    "\n",
    "# config['inDataPath'] = '../../data/bci42a/rawPython'\n",
    "# config['inLabelPath'] = '../../data//bci42a/rawPython/dataLabels.csv'\n",
    "# ROOT_PATH = '../../output/bci42a/ses2Test/eegnet_cross_subject/'\n",
    "# net = eegNet(**config['modelArguments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = eegDataset(dataPath = config['inDataPath'], dataLabelsPath= config['inLabelPath'], preloadData = False, transform= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_sub, data, model, session='1'):\n",
    "        subIdxTest = [i for i, x in enumerate(data.labels) if x[3] in test_sub and x[4] == session]\n",
    "        testData = copy.deepcopy(data)\n",
    "        testData.createPartialDataset(subIdxTest, loadNonLoadedData = True)\n",
    "\n",
    "        testResults, pred, act, pred_prob = model.test_preds(testData)\n",
    "\n",
    "        del testData\n",
    "        gc.collect()\n",
    "\n",
    "        return testResults, pred, act, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing subject 001 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.7048611111111112, 'cm': array([[51,  9, 11,  1],\n",
      "       [21, 45,  6,  0],\n",
      "       [ 1,  0, 54, 17],\n",
      "       [ 0,  0, 19, 53]]), 'loss': 0.6606802940368652}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.6909722222222222, 'cm': array([[41, 15, 10,  6],\n",
      "       [ 8, 61,  3,  0],\n",
      "       [ 1,  0, 45, 26],\n",
      "       [ 0,  0, 20, 52]]), 'loss': 0.6937871509128146}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.7465277777777778, 'cm': array([[58,  4,  9,  1],\n",
      "       [12, 56,  4,  0],\n",
      "       [ 2,  1, 59, 10],\n",
      "       [ 1,  0, 29, 42]]), 'loss': 0.6049310896131728}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.6666666666666666, 'cm': array([[51,  7,  8,  6],\n",
      "       [20, 43,  9,  0],\n",
      "       [ 2,  0, 37, 33],\n",
      "       [ 0,  0, 11, 61]]), 'loss': 0.6990844938490126}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.6006944444444444, 'cm': array([[64,  1,  6,  1],\n",
      "       [45, 18,  9,  0],\n",
      "       [ 5,  0, 42, 25],\n",
      "       [ 0,  0, 23, 49]]), 'loss': 0.742124080657959}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.7430555555555556, 'cm': array([[59,  2,  6,  5],\n",
      "       [24, 44,  4,  0],\n",
      "       [ 1,  0, 65,  6],\n",
      "       [ 0,  0, 26, 46]]), 'loss': 0.6115825441148546}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.6354166666666666, 'cm': array([[62,  1,  9,  0],\n",
      "       [38, 23, 11,  0],\n",
      "       [ 2,  0, 58, 12],\n",
      "       [ 0,  0, 32, 40]]), 'loss': 0.7668737835354276}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.7465277777777778, 'cm': array([[60,  5,  5,  2],\n",
      "       [13, 52,  7,  0],\n",
      "       [ 5,  0, 55, 12],\n",
      "       [ 1,  0, 23, 48]]), 'loss': 0.5870521863301595}\n",
      "Theoretical max accuracy: 0.96875\n",
      "Testing subject 002 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.4583333333333333, 'cm': array([[19, 26, 24,  3],\n",
      "       [ 6, 40, 16, 10],\n",
      "       [ 2,  6, 64,  0],\n",
      "       [14, 24, 25,  9]]), 'loss': 1.26515441470676}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.4965277777777778, 'cm': array([[35,  3, 30,  4],\n",
      "       [19, 16, 31,  6],\n",
      "       [ 1,  0, 69,  2],\n",
      "       [18,  9, 22, 23]]), 'loss': 1.2325933244493272}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.4583333333333333, 'cm': array([[26, 24, 15,  7],\n",
      "       [22, 34, 12,  4],\n",
      "       [ 4,  5, 63,  0],\n",
      "       [22, 29, 12,  9]]), 'loss': 1.1804112328423395}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.4375, 'cm': array([[24, 30, 16,  2],\n",
      "       [19, 36, 11,  6],\n",
      "       [ 6, 12, 52,  2],\n",
      "       [20, 25, 13, 14]]), 'loss': 1.2247094048394098}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.4652777777777778, 'cm': array([[10,  8, 30, 24],\n",
      "       [10, 15, 23, 24],\n",
      "       [ 1,  2, 68,  1],\n",
      "       [ 8,  9, 14, 41]]), 'loss': 1.2528582678900824}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.5034722222222222, 'cm': array([[42, 11, 14,  5],\n",
      "       [31, 25, 10,  6],\n",
      "       [ 4,  3, 62,  3],\n",
      "       [34, 14,  8, 16]]), 'loss': 1.1183867984347873}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.5, 'cm': array([[28, 29, 12,  3],\n",
      "       [16, 43,  7,  6],\n",
      "       [ 5,  4, 60,  3],\n",
      "       [23, 29,  7, 13]]), 'loss': 1.172980096605089}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.4756944444444444, 'cm': array([[30, 26, 13,  3],\n",
      "       [30, 32,  6,  4],\n",
      "       [ 7,  4, 60,  1],\n",
      "       [24, 24,  9, 15]]), 'loss': 1.1395355860392253}\n",
      "Theoretical max accuracy: 0.8333333333333334\n",
      "Testing subject 003 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.8229166666666666, 'cm': array([[52,  8,  3,  9],\n",
      "       [ 0, 70,  0,  2],\n",
      "       [ 0,  5, 49, 18],\n",
      "       [ 1,  1,  4, 66]]), 'loss': 0.4898236592610677}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.7881944444444444, 'cm': array([[62,  7,  3,  0],\n",
      "       [ 3, 69,  0,  0],\n",
      "       [ 8, 13, 44,  7],\n",
      "       [ 6,  2, 12, 52]]), 'loss': 0.581877867380778}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.8229166666666666, 'cm': array([[64,  2,  5,  1],\n",
      "       [ 2, 66,  3,  1],\n",
      "       [ 6,  4, 45, 17],\n",
      "       [ 5,  1,  4, 62]]), 'loss': 0.5377021895514594}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.7777777777777778, 'cm': array([[54, 12,  4,  2],\n",
      "       [ 1, 69,  1,  1],\n",
      "       [ 4, 17, 36, 15],\n",
      "       [ 5,  1,  1, 65]]), 'loss': 0.6016759342617459}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.78125, 'cm': array([[55,  1, 11,  5],\n",
      "       [ 9, 51,  9,  3],\n",
      "       [ 3,  1, 53, 15],\n",
      "       [ 1,  0,  5, 66]]), 'loss': 0.6244690153333876}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.7847222222222222, 'cm': array([[59, 11,  1,  1],\n",
      "       [ 2, 70,  0,  0],\n",
      "       [ 9, 11, 49,  3],\n",
      "       [ 9,  3, 12, 48]]), 'loss': 0.6138793627421061}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.7361111111111112, 'cm': array([[57,  7,  0,  8],\n",
      "       [ 8, 59,  0,  5],\n",
      "       [ 7, 11, 26, 28],\n",
      "       [ 0,  1,  1, 70]]), 'loss': 0.6888613171047635}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.8229166666666666, 'cm': array([[69,  3,  0,  0],\n",
      "       [ 2, 68,  2,  0],\n",
      "       [ 6, 11, 43, 12],\n",
      "       [ 3,  1, 11, 57]]), 'loss': 0.492451720767551}\n",
      "Theoretical max accuracy: 0.9826388888888888\n",
      "Testing subject 004 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.5451388888888888, 'cm': array([[37, 30,  0,  5],\n",
      "       [ 7, 61,  0,  4],\n",
      "       [ 9, 18, 16, 29],\n",
      "       [ 6, 23,  0, 43]]), 'loss': 1.0261107550726996}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.6770833333333334, 'cm': array([[50, 12,  8,  2],\n",
      "       [12, 46, 10,  4],\n",
      "       [ 4,  3, 55, 10],\n",
      "       [ 6,  8, 14, 44]]), 'loss': 0.9313543107774522}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.5208333333333334, 'cm': array([[55, 12,  1,  4],\n",
      "       [21, 47,  1,  3],\n",
      "       [27, 14, 19, 12],\n",
      "       [22, 20,  1, 29]]), 'loss': 1.1056012047661676}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.6006944444444444, 'cm': array([[52, 15,  1,  4],\n",
      "       [19, 41,  4,  8],\n",
      "       [ 5, 11, 32, 24],\n",
      "       [ 7, 12,  5, 48]]), 'loss': 0.9371049669053819}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.5625, 'cm': array([[60,  5,  4,  3],\n",
      "       [36, 28,  7,  1],\n",
      "       [14,  4, 41, 13],\n",
      "       [18,  8, 13, 33]]), 'loss': 0.990947405497233}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.6354166666666666, 'cm': array([[63,  5,  1,  3],\n",
      "       [22, 41,  2,  7],\n",
      "       [13,  7, 32, 20],\n",
      "       [12, 10,  3, 47]]), 'loss': 0.9155874252319336}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.5381944444444444, 'cm': array([[42,  8, 19,  3],\n",
      "       [15, 29, 20,  8],\n",
      "       [ 6,  3, 40, 23],\n",
      "       [11,  2, 15, 44]]), 'loss': 1.0440571043226454}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.5416666666666666, 'cm': array([[34, 24,  6,  8],\n",
      "       [16, 41,  7,  8],\n",
      "       [ 5,  7, 26, 34],\n",
      "       [ 3, 12,  2, 55]]), 'loss': 1.0457563400268555}\n",
      "Theoretical max accuracy: 0.9756944444444444\n",
      "Testing subject 005 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.4444444444444444, 'cm': array([[23, 30, 18,  1],\n",
      "       [ 1, 69,  1,  1],\n",
      "       [ 9, 38, 24,  1],\n",
      "       [ 3, 33, 24, 12]]), 'loss': 1.267695215013292}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.53125, 'cm': array([[22, 24, 10, 16],\n",
      "       [ 7, 50,  4, 11],\n",
      "       [ 5, 21, 28, 18],\n",
      "       [ 3, 12,  4, 53]]), 'loss': 1.099339485168457}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.5243055555555556, 'cm': array([[58, 12,  0,  2],\n",
      "       [26, 42,  0,  4],\n",
      "       [32, 15, 13, 12],\n",
      "       [25,  7,  2, 38]]), 'loss': 1.1250243716769748}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.5243055555555556, 'cm': array([[31,  2, 17, 22],\n",
      "       [19, 17, 10, 26],\n",
      "       [ 9,  2, 45, 16],\n",
      "       [ 7,  0,  7, 58]]), 'loss': 1.157441669040256}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.4861111111111111, 'cm': array([[37,  3,  8, 24],\n",
      "       [21, 20,  8, 23],\n",
      "       [13,  1, 25, 33],\n",
      "       [ 9,  0,  5, 58]]), 'loss': 1.1339172787136502}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.5034722222222222, 'cm': array([[48,  2,  3, 19],\n",
      "       [18, 38,  2, 14],\n",
      "       [21,  6,  8, 37],\n",
      "       [14,  5,  2, 51]]), 'loss': 1.1408924526638455}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.4340277777777778, 'cm': array([[44,  5,  1, 22],\n",
      "       [30, 21,  0, 21],\n",
      "       [19,  3, 12, 38],\n",
      "       [14,  4,  6, 48]]), 'loss': 1.25010257297092}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.4340277777777778, 'cm': array([[70,  2,  0,  0],\n",
      "       [39, 29,  3,  1],\n",
      "       [52,  6, 12,  2],\n",
      "       [39, 10,  9, 14]]), 'loss': 1.3059506946139865}\n",
      "Theoretical max accuracy: 0.9513888888888888\n",
      "Testing subject 006 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.4270833333333333, 'cm': array([[49,  5,  5, 13],\n",
      "       [31, 19,  3, 19],\n",
      "       [20,  4, 18, 30],\n",
      "       [20, 12,  3, 37]]), 'loss': 1.2636160320705838}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.4826388888888889, 'cm': array([[45, 17,  9,  1],\n",
      "       [17, 45, 10,  0],\n",
      "       [16, 12, 41,  3],\n",
      "       [23, 27, 14,  8]]), 'loss': 1.332342677646213}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.4444444444444444, 'cm': array([[41, 20,  6,  5],\n",
      "       [22, 40,  4,  6],\n",
      "       [13, 16, 28, 15],\n",
      "       [21, 31,  1, 19]]), 'loss': 1.2030584547254775}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.4131944444444444, 'cm': array([[26, 32,  2, 12],\n",
      "       [10, 55,  0,  7],\n",
      "       [ 8, 28, 10, 26],\n",
      "       [11, 33,  0, 28]]), 'loss': 1.3188594182332356}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.4826388888888889, 'cm': array([[46, 10,  6, 10],\n",
      "       [22, 32,  5, 13],\n",
      "       [15,  9, 29, 19],\n",
      "       [25,  9,  6, 32]]), 'loss': 1.2166225645277235}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.3958333333333333, 'cm': array([[53, 11,  1,  7],\n",
      "       [41, 28,  2,  1],\n",
      "       [23, 21, 18, 10],\n",
      "       [29, 27,  1, 15]]), 'loss': 1.3235370847913954}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.4965277777777778, 'cm': array([[39, 12,  8, 13],\n",
      "       [18, 32, 10, 12],\n",
      "       [ 8,  8, 35, 21],\n",
      "       [12, 12, 11, 37]]), 'loss': 1.1979469723171658}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.4409722222222222, 'cm': array([[45, 13,  4, 10],\n",
      "       [30, 32,  4,  6],\n",
      "       [13, 12, 23, 24],\n",
      "       [20, 21,  4, 27]]), 'loss': 1.2582420772976346}\n",
      "Theoretical max accuracy: 0.8506944444444444\n",
      "Testing subject 007 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.7013888888888888, 'cm': array([[39, 14,  4, 15],\n",
      "       [ 4, 48, 11,  9],\n",
      "       [ 0,  2, 48, 22],\n",
      "       [ 0,  0,  5, 67]]), 'loss': 0.7824184629652235}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.5381944444444444, 'cm': array([[14, 18,  1, 39],\n",
      "       [ 2, 33,  1, 36],\n",
      "       [ 0,  0, 37, 35],\n",
      "       [ 1,  0,  0, 71]]), 'loss': 1.1220164828830295}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.6388888888888888, 'cm': array([[40, 13,  3, 16],\n",
      "       [16, 29,  7, 20],\n",
      "       [ 1,  2, 49, 20],\n",
      "       [ 0,  0,  6, 66]]), 'loss': 0.83221345477634}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.7118055555555556, 'cm': array([[45, 13,  1, 13],\n",
      "       [10, 52,  2,  8],\n",
      "       [ 2,  4, 40, 26],\n",
      "       [ 0,  2,  2, 68]]), 'loss': 0.7287325859069824}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.6666666666666666, 'cm': array([[32, 22,  2, 16],\n",
      "       [ 8, 55,  0,  9],\n",
      "       [ 0,  0, 37, 35],\n",
      "       [ 0,  1,  3, 68]]), 'loss': 0.7588997946845161}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.7083333333333334, 'cm': array([[27, 26,  2, 17],\n",
      "       [ 2, 59,  2,  9],\n",
      "       [ 2,  4, 48, 18],\n",
      "       [ 0,  1,  1, 70]]), 'loss': 0.7643464406331381}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.59375, 'cm': array([[19, 34,  3, 16],\n",
      "       [ 4, 48,  6, 14],\n",
      "       [ 2, 10, 43, 17],\n",
      "       [ 0,  7,  4, 61]]), 'loss': 0.9059296713935004}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.625, 'cm': array([[40, 16,  2, 14],\n",
      "       [10, 34,  7, 21],\n",
      "       [ 0,  2, 42, 28],\n",
      "       [ 1,  1,  6, 64]]), 'loss': 0.8559280501471626}\n",
      "Theoretical max accuracy: 0.9305555555555556\n",
      "Testing subject 008 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.6701388888888888, 'cm': array([[45,  1, 26,  0],\n",
      "       [ 0, 53, 18,  1],\n",
      "       [ 6,  3, 51, 12],\n",
      "       [ 4,  5, 19, 44]]), 'loss': 0.7709805170694987}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.6666666666666666, 'cm': array([[41,  1, 30,  0],\n",
      "       [ 0, 45, 24,  3],\n",
      "       [ 5,  2, 61,  4],\n",
      "       [ 5,  3, 19, 45]]), 'loss': 0.7551488346523709}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.7118055555555556, 'cm': array([[65,  1,  2,  4],\n",
      "       [ 2, 54,  5, 11],\n",
      "       [16,  7, 30, 19],\n",
      "       [10,  5,  1, 56]]), 'loss': 0.7382417784796821}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.6840277777777778, 'cm': array([[62,  6,  3,  1],\n",
      "       [ 0, 70,  0,  2],\n",
      "       [10, 31, 17, 14],\n",
      "       [ 5, 19,  0, 48]]), 'loss': 0.8141160541110568}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.7083333333333334, 'cm': array([[55,  2, 14,  1],\n",
      "       [ 2, 49, 17,  4],\n",
      "       [ 7,  2, 52, 11],\n",
      "       [ 7,  3, 14, 48]]), 'loss': 0.749795224931505}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.6423611111111112, 'cm': array([[56,  0, 16,  0],\n",
      "       [ 0, 51, 20,  1],\n",
      "       [12,  4, 53,  3],\n",
      "       [13,  8, 26, 25]]), 'loss': 0.8689548704359267}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.6666666666666666, 'cm': array([[69,  1,  2,  0],\n",
      "       [ 3, 63,  4,  2],\n",
      "       [32,  5, 26,  9],\n",
      "       [27,  6,  5, 34]]), 'loss': 0.8211832576327853}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.6944444444444444, 'cm': array([[64,  1,  7,  0],\n",
      "       [ 4, 54, 12,  2],\n",
      "       [13,  2, 54,  3],\n",
      "       [20, 12, 12, 28]]), 'loss': 0.8535082605150011}\n",
      "Theoretical max accuracy: 0.9375\n",
      "Testing subject 009 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.6354166666666666, 'cm': array([[51, 19,  1,  1],\n",
      "       [ 6, 53,  2, 11],\n",
      "       [ 5, 27, 18, 22],\n",
      "       [ 0,  9,  2, 61]]), 'loss': 0.8399595684475369}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.6805555555555556, 'cm': array([[70,  1,  1,  0],\n",
      "       [13, 51,  6,  2],\n",
      "       [20, 22, 27,  3],\n",
      "       [ 4, 12,  8, 48]]), 'loss': 0.843417591518826}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.71875, 'cm': array([[65,  4,  1,  2],\n",
      "       [ 8, 48,  1, 15],\n",
      "       [ 8, 18, 27, 19],\n",
      "       [ 2,  3,  0, 67]]), 'loss': 0.6911504533555772}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.6770833333333334, 'cm': array([[64,  4,  3,  1],\n",
      "       [10, 44, 10,  8],\n",
      "       [ 9, 14, 28, 21],\n",
      "       [ 0,  6,  7, 59]]), 'loss': 0.7571341726515028}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.6979166666666666, 'cm': array([[57, 12,  3,  0],\n",
      "       [ 8, 54,  8,  2],\n",
      "       [ 3, 18, 46,  5],\n",
      "       [ 1, 20,  7, 44]]), 'loss': 0.7005608346727159}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.6770833333333334, 'cm': array([[58, 13,  1,  0],\n",
      "       [ 7, 48, 10,  7],\n",
      "       [ 3, 22, 30, 17],\n",
      "       [ 0, 11,  2, 59]]), 'loss': 0.8125386238098145}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.59375, 'cm': array([[60,  8,  0,  4],\n",
      "       [ 9, 29,  1, 33],\n",
      "       [ 9, 16, 14, 33],\n",
      "       [ 0,  3,  1, 68]]), 'loss': 0.9135962592230903}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.7430555555555556, 'cm': array([[63,  3,  6,  0],\n",
      "       [10, 33, 22,  7],\n",
      "       [ 4,  0, 66,  2],\n",
      "       [ 1,  6, 13, 52]]), 'loss': 0.6958628760443794}\n",
      "Theoretical max accuracy: 0.9652777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    }
   ],
   "source": [
    "subs = list(range(9))\n",
    "accs = []\n",
    "all_preds = {}\n",
    "all_pred_probs = {}\n",
    "all_losses = {}\n",
    "all_test_results = {}\n",
    "all_acts = {}\n",
    "all_train_preds = {}\n",
    "all_train_pred_probs = {}\n",
    "all_train_losses = {}\n",
    "all_train_results = {}\n",
    "for test_sub in subs:\n",
    "    test_sub_str = '00' + str(test_sub + 1)\n",
    "    preds = []\n",
    "    pred_probs = []\n",
    "    train_preds = []\n",
    "    train_pred_probs = []\n",
    "    results = {}\n",
    "    train_results = {}\n",
    "    train_losses = []\n",
    "    print(\"Testing subject \" + test_sub_str + \" with all models...\")\n",
    "    for sub in subs:\n",
    "        if(sub == test_sub):\n",
    "            continue\n",
    "#             state_dict_path = os.path.join(ROOT_PATH, 'sub' + str(sub), 'network_state_dict.pth'\n",
    "        else:\n",
    "            state_dict_path = os.path.join(ROOT_PATH, 'sub' + str(sub), 'finetuned_sub' + str(test_sub), 'network_state_dict.pth')\n",
    "    #     print(state_dict_path)\n",
    "        netInitState = torch.load(state_dict_path)\n",
    "        net.load_state_dict(netInitState, strict=False)\n",
    "        outPathSub = None\n",
    "        model = baseModel(net=net, resultsSavePath=outPathSub, batchSize= config['batchSize'], nGPU = nGPU)\n",
    "        testResults, pred, act, pred_prob = test_model(test_sub_str, data, model, session='0')\n",
    "        train_preds.append(pred)\n",
    "        train_pred_probs.append(pred_prob)\n",
    "        train_results[sub] = testResults\n",
    "        train_losses.append(testResults['loss'])\n",
    "        \n",
    "        testResults, pred, act, pred_prob = test_model(test_sub_str, data, model)\n",
    "        preds.append(pred)\n",
    "        pred_probs.append(pred_prob)\n",
    "        results[sub] = testResults\n",
    "        print(\"Results for model\", sub, testResults)\n",
    "    \n",
    "    correct = 0\n",
    "    for i in range(len(act)):\n",
    "        for pred in preds:\n",
    "            if(pred[i] == act[i]):\n",
    "                correct += 1\n",
    "                break\n",
    "    \n",
    "    all_preds[test_sub] = preds\n",
    "    all_pred_probs[test_sub] = pred_probs\n",
    "    all_acts[test_sub] = act\n",
    "    all_test_results[test_sub] = results\n",
    "    \n",
    "    all_train_preds[test_sub] = train_preds\n",
    "    all_train_pred_probs[test_sub] = train_pred_probs\n",
    "    all_train_losses[test_sub] = train_losses\n",
    "    all_train_results[test_sub] = train_results\n",
    "    \n",
    "    acc = correct/len(act)\n",
    "    accs.append(acc)\n",
    "    print(\"Theoretical max accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.96875,\n",
       " 0.8333333333333334,\n",
       " 0.9826388888888888,\n",
       " 0.9756944444444444,\n",
       " 0.9513888888888888,\n",
       " 0.8506944444444444,\n",
       " 0.9305555555555556,\n",
       " 0.9375,\n",
       " 0.9652777777777778]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average theoretical max accuracy: 0.9328703703703705\n"
     ]
    }
   ],
   "source": [
    "avg_acc = sum(accs) / len(accs)\n",
    "print(\"Average theoretical max accuracy:\", avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.875 & 83.333 & 98.264 & 97.569 & 95.139 & 85.069 & 93.056 & 93.750 & 96.528 & 93.287\n"
     ]
    }
   ],
   "source": [
    "accs.append(avg_acc)\n",
    "tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_spec_accs = [all_test_results[i][i]['acc'] for i in range(9)]\n",
    "# print(sub_spec_accs)\n",
    "# print(\"Subject specific average accuracy:\", sum(sub_spec_accs) / len(sub_spec_accs))\n",
    "# print(\"Subject specific median accuracy:\", statistics.median(sub_spec_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voted accuracy: 0.7604166666666666\n",
      "Voted accuracy: 0.4895833333333333\n",
      "Voted accuracy: 0.8680555555555556\n",
      "Voted accuracy: 0.6701388888888888\n",
      "Voted accuracy: 0.5868055555555556\n",
      "Voted accuracy: 0.4965277777777778\n",
      "Voted accuracy: 0.7326388888888888\n",
      "Voted accuracy: 0.7638888888888888\n",
      "Voted accuracy: 0.7326388888888888\n",
      "Average voted accuracy: 0.6778549382716049\n",
      "Median voted accuracy: 0.7326388888888888\n",
      "76.042 & 48.958 & 86.806 & 67.014 & 58.681 & 49.653 & 73.264 & 76.389 & 73.264 & 67.785\n"
     ]
    }
   ],
   "source": [
    "voted_accs = []\n",
    "for test_sub in subs:\n",
    "    voted_pred = []\n",
    "#     test_sub = 1\n",
    "    preds = all_preds[test_sub]\n",
    "    act = all_acts[test_sub]\n",
    "    for i in range(len(preds[0])):\n",
    "        votes = {l:0 for l in range(4)}\n",
    "        for pred in preds:\n",
    "            votes[pred[i]]+=1\n",
    "        voted_pred.append(max(votes, key=votes.get))\n",
    "\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(voted_pred, act):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(act)\n",
    "    voted_accs.append(voted_acc)\n",
    "    print(\"Voted accuracy:\", voted_acc)\n",
    "    \n",
    "avg_voted_acc = sum(voted_accs) / len(voted_accs)\n",
    "print(\"Average voted accuracy:\", avg_voted_acc)\n",
    "print(\"Median voted accuracy:\", statistics.median(voted_accs))\n",
    "voted_accs.append(avg_voted_acc)\n",
    "tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in voted_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft probability combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.67976022 -2.74977493 -1.1609484  -2.15304303]\n",
      " [-1.71839952 -0.47889972 -1.74232936 -3.64695525]\n",
      " [-1.10272312 -1.02841139 -2.03122544 -1.71877861]\n",
      " ...\n",
      " [-1.89518547 -4.48982334 -1.42056894 -0.51598835]\n",
      " [-0.10611355 -2.39744759 -4.72413921 -7.07113075]\n",
      " [-4.5509696  -4.95780516 -0.20472459 -1.78651571]]\n",
      "[[ -5.91000694 -28.71125102  -9.29190612 -16.84640241]\n",
      " [-19.35394633  -5.66360605 -10.27750057 -30.72827196]\n",
      " [ -9.31741679  -9.94278952 -17.63026929 -23.69747281]\n",
      " ...\n",
      " [-17.95968223 -39.18070722  -6.15930805  -8.44704628]\n",
      " [ -1.8375022  -15.86443311 -34.48160219 -61.45547819]\n",
      " [-35.56507182 -38.08611655  -5.60815676  -8.73323737]]\n",
      "Soft probability combined accuracy: 0.7743055555555556\n",
      "Average combined accuracy: 0.7743055555555556\n",
      "Median combined accuracy: 0.7743055555555556\n",
      "77.431\n",
      "77.431\n"
     ]
    }
   ],
   "source": [
    "comb_accs = []\n",
    "for test_sub in subs:\n",
    "    pred_probs = np.array(all_pred_probs[test_sub])\n",
    "    n, h, w, c = pred_probs.shape\n",
    "    pred_probs = np.reshape(pred_probs, (n, h*w, c))\n",
    "    print(pred_probs[0])\n",
    "    class_probs = np.sum(pred_probs, axis=0)\n",
    "    print(class_probs)\n",
    "    soft_preds = np.argmax(class_probs, axis=1)\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(soft_preds, all_acts[test_sub]):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(all_acts[test_sub])\n",
    "    comb_accs.append(voted_acc)\n",
    "    print(\"Soft probability combined accuracy:\", voted_acc)\n",
    "    break\n",
    "\n",
    "avg_comb_acc = sum(comb_accs) / len(comb_accs)\n",
    "print(\"Average combined accuracy:\", avg_comb_acc)\n",
    "print(\"Median combined accuracy:\", statistics.median(comb_accs))\n",
    "comb_accs.append(avg_comb_acc)\n",
    "tabstr = '\\n'.join([\"{0:.3f}\".format(x*100) for x in comb_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {test_sub: {train_sub: results['cm'] for train_sub, results in test_results.items()} for test_sub, test_results in all_train_results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {test_sub: {train_sub: np.array([cm[i][i]/np.sum(cm[i,:]) for i in range(4)]) for train_sub, cm in test_results.items()} for test_sub, test_results in cms.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {1: array([1., 1., 1., 1.]),\n",
       "  2: array([0.94444444, 1.        , 0.97222222, 0.98611111]),\n",
       "  3: array([1.        , 0.98611111, 1.        , 0.95833333]),\n",
       "  4: array([0.98611111, 0.98611111, 0.98611111, 1.        ]),\n",
       "  5: array([1.        , 0.91666667, 1.        , 1.        ]),\n",
       "  6: array([1.        , 1.        , 0.98611111, 0.98611111]),\n",
       "  7: array([1.        , 0.88888889, 1.        , 0.97222222]),\n",
       "  8: array([1., 1., 1., 1.])},\n",
       " 1: {0: array([0.91666667, 0.93055556, 1.        , 0.88888889]),\n",
       "  2: array([0.94444444, 0.95833333, 1.        , 0.95833333]),\n",
       "  3: array([0.90277778, 1.        , 1.        , 0.97222222]),\n",
       "  4: array([0.98611111, 1.        , 1.        , 0.97222222]),\n",
       "  5: array([0.88888889, 0.98611111, 1.        , 1.        ]),\n",
       "  6: array([0.98611111, 0.90277778, 1.        , 1.        ]),\n",
       "  7: array([0.83333333, 1.        , 1.        , 0.94444444]),\n",
       "  8: array([1.        , 1.        , 1.        , 0.95833333])},\n",
       " 2: {0: array([1.        , 1.        , 0.97222222, 1.        ]),\n",
       "  1: array([1., 1., 1., 1.]),\n",
       "  3: array([1.        , 1.        , 0.95833333, 1.        ]),\n",
       "  4: array([1.        , 1.        , 0.91666667, 1.        ]),\n",
       "  5: array([1.        , 0.94444444, 1.        , 1.        ]),\n",
       "  6: array([1.        , 1.        , 0.98611111, 0.91666667]),\n",
       "  7: array([0.98611111, 1.        , 0.91666667, 1.        ]),\n",
       "  8: array([1., 1., 1., 1.])},\n",
       " 3: {0: array([1.        , 1.        , 0.40277778, 0.98611111]),\n",
       "  1: array([1., 1., 1., 1.]),\n",
       "  2: array([1.        , 0.93055556, 0.81944444, 0.90277778]),\n",
       "  4: array([1.        , 0.98611111, 0.97222222, 0.95833333]),\n",
       "  5: array([1.        , 0.98611111, 0.98611111, 0.88888889]),\n",
       "  6: array([1.        , 0.90277778, 0.84722222, 0.98611111]),\n",
       "  7: array([1.        , 0.94444444, 0.98611111, 0.93055556]),\n",
       "  8: array([0.95833333, 0.97222222, 0.86111111, 0.97222222])},\n",
       " 4: {0: array([0.79166667, 1.        , 1.        , 0.65277778]),\n",
       "  1: array([0.98611111, 1.        , 1.        , 1.        ]),\n",
       "  2: array([1.        , 0.98611111, 0.95833333, 0.91666667]),\n",
       "  3: array([0.97222222, 0.91666667, 1.        , 0.98611111]),\n",
       "  5: array([0.97222222, 1.        , 0.98611111, 1.        ]),\n",
       "  6: array([1.        , 0.95833333, 0.97222222, 1.        ]),\n",
       "  7: array([1.        , 0.97222222, 0.95833333, 1.        ]),\n",
       "  8: array([0.98611111, 1.        , 1.        , 0.97222222])},\n",
       " 5: {0: array([0.97222222, 0.95833333, 0.90277778, 1.        ]),\n",
       "  1: array([0.95833333, 0.98611111, 1.        , 0.76388889]),\n",
       "  2: array([0.97222222, 1.        , 0.95833333, 0.97222222]),\n",
       "  3: array([0.93055556, 1.        , 0.80555556, 0.98611111]),\n",
       "  4: array([0.98611111, 1.        , 0.95833333, 0.97222222]),\n",
       "  6: array([0.97222222, 0.98611111, 0.875     , 0.93055556]),\n",
       "  7: array([0.875     , 0.88888889, 0.98611111, 0.98611111]),\n",
       "  8: array([0.94444444, 1.        , 0.94444444, 1.        ])},\n",
       " 6: {0: array([1.        , 1.        , 1.        , 0.97222222]),\n",
       "  1: array([0.98611111, 1.        , 1.        , 1.        ]),\n",
       "  2: array([1.        , 1.        , 0.98611111, 0.95833333]),\n",
       "  3: array([1., 1., 1., 1.]),\n",
       "  4: array([1.        , 1.        , 1.        , 0.98611111]),\n",
       "  5: array([1.        , 1.        , 1.        , 0.98611111]),\n",
       "  7: array([0.90277778, 1.        , 0.84722222, 0.86111111]),\n",
       "  8: array([1.        , 0.98611111, 1.        , 1.        ])},\n",
       " 7: {0: array([0.91666667, 0.98611111, 1.        , 0.98611111]),\n",
       "  1: array([1.        , 0.97222222, 1.        , 0.98611111]),\n",
       "  2: array([1.        , 0.97222222, 0.94444444, 1.        ]),\n",
       "  3: array([1.        , 1.        , 0.86111111, 0.98611111]),\n",
       "  4: array([1., 1., 1., 1.]),\n",
       "  5: array([1.        , 1.        , 1.        , 0.98611111]),\n",
       "  6: array([1.        , 1.        , 0.97222222, 1.        ]),\n",
       "  8: array([1.        , 0.98611111, 1.        , 0.94444444])},\n",
       " 8: {0: array([1.        , 1.        , 0.86111111, 1.        ]),\n",
       "  1: array([1.        , 0.98611111, 0.91666667, 0.94444444]),\n",
       "  2: array([1.        , 0.95833333, 0.88888889, 1.        ]),\n",
       "  3: array([1.        , 1.        , 0.98611111, 1.        ]),\n",
       "  4: array([1.        , 1.        , 0.97222222, 0.98611111]),\n",
       "  5: array([1.        , 1.        , 0.93055556, 1.        ]),\n",
       "  6: array([1.        , 0.97222222, 0.81944444, 1.        ]),\n",
       "  7: array([1.        , 0.90277778, 1.        , 0.90277778])}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_sums = {test_sub: np.array([np.sum(recalls) for train_sub, recalls in test_results.items()]) for test_sub, test_results in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.        , 3.90277778, 3.94444444, 3.95833333, 3.91666667,\n",
       "       3.97222222, 3.86111111, 4.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_sums[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 4, 2, 3, 5, 0, 7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(recall_sums[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft probability combined accuracy: 0.7777777777777778\n",
      "Soft probability combined accuracy: 0.5138888888888888\n",
      "Soft probability combined accuracy: 0.875\n",
      "Soft probability combined accuracy: 0.7118055555555556\n",
      "Soft probability combined accuracy: 0.65625\n",
      "Soft probability combined accuracy: 0.5104166666666666\n",
      "Soft probability combined accuracy: 0.7256944444444444\n",
      "Soft probability combined accuracy: 0.7673611111111112\n",
      "Soft probability combined accuracy: 0.7604166666666666\n",
      "Average combined accuracy: 0.6998456790123457\n",
      "Median combined accuracy: 0.7256944444444444\n",
      "77.778\n",
      "51.389\n",
      "87.500\n",
      "71.181\n",
      "65.625\n",
      "51.042\n",
      "72.569\n",
      "76.736\n",
      "76.042\n",
      "69.985\n"
     ]
    }
   ],
   "source": [
    "comb_accs = []\n",
    "for test_sub in subs:\n",
    "    mlist = list(range(9))\n",
    "    mlist.pop(test_sub)\n",
    "    pred_probs = np.array(all_pred_probs[test_sub])\n",
    "    n, h, w, c = pred_probs.shape\n",
    "    pred_probs = np.reshape(pred_probs, (n, h*w, c))\n",
    "#     print(pred_probs)\n",
    "    for i in range(len(pred_probs)):\n",
    "#         print(pred_probs[i])\n",
    "        for j in range(len(pred_probs[i])):\n",
    "            pred_probs[i][j] = np.multiply(pred_probs[i][j], metrics[test_sub][mlist[i]])\n",
    "    class_probs = np.sum(pred_probs, axis=0)\n",
    "    soft_preds = np.argmax(class_probs, axis=1)\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(soft_preds, all_acts[test_sub]):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(all_acts[test_sub])\n",
    "    comb_accs.append(voted_acc)\n",
    "    print(\"Soft probability combined accuracy:\", voted_acc)\n",
    "\n",
    "avg_comb_acc = sum(comb_accs) / len(comb_accs)\n",
    "print(\"Average combined accuracy:\", avg_comb_acc)\n",
    "print(\"Median combined accuracy:\", statistics.median(comb_accs))\n",
    "comb_accs.append(avg_comb_acc)\n",
    "tabstr = '\\n'.join([\"{0:.3f}\".format(x*100) for x in comb_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voted accuracy: 0.7604166666666666\n",
      "Voted accuracy: 0.4895833333333333\n",
      "Voted accuracy: 0.875\n",
      "Voted accuracy: 0.6527777777777778\n",
      "Voted accuracy: 0.5763888888888888\n",
      "Voted accuracy: 0.5243055555555556\n",
      "Voted accuracy: 0.7222222222222222\n",
      "Voted accuracy: 0.7604166666666666\n",
      "Voted accuracy: 0.7291666666666666\n",
      "Average voted accuracy: 0.6766975308641976\n",
      "Median voted accuracy: 0.7222222222222222\n",
      "76.042 & 48.958 & 87.500 & 65.278 & 57.639 & 52.431 & 72.222 & 76.042 & 72.917 & 67.670\n"
     ]
    }
   ],
   "source": [
    "voted_accs = []\n",
    "for test_sub in subs:\n",
    "    voted_pred = []\n",
    "    mlist = list(range(9))\n",
    "    mlist.pop(test_sub)\n",
    "#     test_sub = 1\n",
    "    preds = all_preds[test_sub]\n",
    "    act = all_acts[test_sub]\n",
    "    for i in range(len(preds[0])):\n",
    "        votes = {l:0 for l in range(4)}\n",
    "        for j, pred in enumerate(preds):\n",
    "            votes[pred[i]]+=metrics[test_sub][mlist[j]][pred[i]]\n",
    "        voted_pred.append(max(votes, key=votes.get))\n",
    "\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(voted_pred, act):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(act)\n",
    "    voted_accs.append(voted_acc)\n",
    "    print(\"Voted accuracy:\", voted_acc)\n",
    "    \n",
    "avg_voted_acc = sum(voted_accs) / len(voted_accs)\n",
    "print(\"Average voted accuracy:\", avg_voted_acc)\n",
    "print(\"Median voted accuracy:\", statistics.median(voted_accs))\n",
    "voted_accs.append(avg_voted_acc)\n",
    "tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in voted_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-2\n",
      "Top recall scaled soft probability combined accuracy: 0.7569444444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.46875\n",
      "Top recall scaled soft probability combined accuracy: 0.8715277777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.7083333333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.5763888888888888\n",
      "Top recall scaled soft probability combined accuracy: 0.5208333333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.75\n",
      "Top recall scaled soft probability combined accuracy: 0.7430555555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.7361111111111112\n",
      "Average combined accuracy: 0.6813271604938271\n",
      "Median combined accuracy: 0.7361111111111112\n",
      "75.694 & 46.875 & 87.153 & 70.833 & 57.639 & 52.083 & 75.000 & 74.306 & 73.611 & 68.133\n",
      "\n",
      "\n",
      "Top-3\n",
      "Top recall scaled soft probability combined accuracy: 0.7743055555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.4722222222222222\n",
      "Top recall scaled soft probability combined accuracy: 0.8229166666666666\n",
      "Top recall scaled soft probability combined accuracy: 0.7152777777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.5972222222222222\n",
      "Top recall scaled soft probability combined accuracy: 0.5243055555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.7083333333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.7430555555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.7326388888888888\n",
      "Average combined accuracy: 0.6766975308641974\n",
      "Median combined accuracy: 0.7152777777777778\n",
      "77.431 & 47.222 & 82.292 & 71.528 & 59.722 & 52.431 & 70.833 & 74.306 & 73.264 & 67.670\n",
      "\n",
      "\n",
      "Top-4\n",
      "Top recall scaled soft probability combined accuracy: 0.7881944444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.5069444444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.8402777777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.5381944444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.6597222222222222\n",
      "Top recall scaled soft probability combined accuracy: 0.5208333333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.7291666666666666\n",
      "Top recall scaled soft probability combined accuracy: 0.7465277777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.7395833333333334\n",
      "Average combined accuracy: 0.6743827160493826\n",
      "Median combined accuracy: 0.7291666666666666\n",
      "78.819 & 50.694 & 84.028 & 53.819 & 65.972 & 52.083 & 72.917 & 74.653 & 73.958 & 67.438\n",
      "\n",
      "\n",
      "Top-5\n",
      "Top recall scaled soft probability combined accuracy: 0.8055555555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.5277777777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.8541666666666666\n",
      "Top recall scaled soft probability combined accuracy: 0.6666666666666666\n",
      "Top recall scaled soft probability combined accuracy: 0.5034722222222222\n",
      "Top recall scaled soft probability combined accuracy: 0.5104166666666666\n",
      "Top recall scaled soft probability combined accuracy: 0.7291666666666666\n",
      "Top recall scaled soft probability combined accuracy: 0.7569444444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.7534722222222222\n",
      "Average combined accuracy: 0.6786265432098766\n",
      "Median combined accuracy: 0.7291666666666666\n",
      "80.556 & 52.778 & 85.417 & 66.667 & 50.347 & 51.042 & 72.917 & 75.694 & 75.347 & 67.863\n",
      "\n",
      "\n",
      "Top-6\n",
      "Top recall scaled soft probability combined accuracy: 0.7916666666666666\n",
      "Top recall scaled soft probability combined accuracy: 0.5138888888888888\n",
      "Top recall scaled soft probability combined accuracy: 0.8715277777777778\n",
      "Top recall scaled soft probability combined accuracy: 0.6597222222222222\n",
      "Top recall scaled soft probability combined accuracy: 0.5729166666666666\n",
      "Top recall scaled soft probability combined accuracy: 0.4791666666666667\n",
      "Top recall scaled soft probability combined accuracy: 0.7256944444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.7534722222222222\n",
      "Top recall scaled soft probability combined accuracy: 0.75\n",
      "Average combined accuracy: 0.6797839506172839\n",
      "Median combined accuracy: 0.7256944444444444\n",
      "79.167 & 51.389 & 87.153 & 65.972 & 57.292 & 47.917 & 72.569 & 75.347 & 75.000 & 67.978\n",
      "\n",
      "\n",
      "Top-7\n",
      "Top recall scaled soft probability combined accuracy: 0.7951388888888888\n",
      "Top recall scaled soft probability combined accuracy: 0.5208333333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.8888888888888888\n",
      "Top recall scaled soft probability combined accuracy: 0.6805555555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.6180555555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.4895833333333333\n",
      "Top recall scaled soft probability combined accuracy: 0.7118055555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.7673611111111112\n",
      "Top recall scaled soft probability combined accuracy: 0.7708333333333334\n",
      "Average combined accuracy: 0.6936728395061729\n",
      "Median combined accuracy: 0.7118055555555556\n",
      "79.514 & 52.083 & 88.889 & 68.056 & 61.806 & 48.958 & 71.181 & 76.736 & 77.083 & 69.367\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,8):\n",
    "    comb_accs = []\n",
    "    print(\"Top-\" + str(i))\n",
    "    for test_sub in subs:\n",
    "        mlist = list(range(9))\n",
    "        mlist.pop(test_sub)\n",
    "        sorted_recall_idx = np.argsort(recall_sums[test_sub])\n",
    "        # print(sorted_recall_idx)\n",
    "        # print(sorted_recall_idx[-5:])\n",
    "        pred_probs = np.array(all_pred_probs[test_sub])\n",
    "        n, h, w, c = pred_probs.shape\n",
    "        pred_probs = np.reshape(pred_probs, (n, h*w, c))\n",
    "    #     print(pred_probs.shape)\n",
    "        pred_probs = np.take(pred_probs, sorted_recall_idx[-i:], 0)\n",
    "    #     print(pred_probs.shape)\n",
    "        for i in range(len(pred_probs)):\n",
    "            for j in range(len(pred_probs[i])):\n",
    "                pred_probs[i][j] = np.multiply(pred_probs[i][j], metrics[test_sub][mlist[i]])\n",
    "        class_probs = np.sum(pred_probs, axis=0)\n",
    "        soft_preds = np.argmax(class_probs, axis=1)\n",
    "        correct = 0\n",
    "        for pred, act_val in zip(soft_preds, all_acts[test_sub]):\n",
    "            if(pred == act_val):\n",
    "                correct += 1\n",
    "        voted_acc = correct / len(all_acts[test_sub])\n",
    "        comb_accs.append(voted_acc)\n",
    "        print(\"Top recall scaled soft probability combined accuracy:\", voted_acc)\n",
    "\n",
    "    avg_comb_acc = sum(comb_accs) / len(comb_accs)\n",
    "    print(\"Average combined accuracy:\", avg_comb_acc)\n",
    "    print(\"Median combined accuracy:\", statistics.median(comb_accs))\n",
    "    comb_accs.append(avg_comb_acc)\n",
    "    tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in comb_accs])\n",
    "    print(tabstr)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
