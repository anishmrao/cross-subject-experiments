{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import xlwt\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# masterPath = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# sys.path.insert(1, os.path.join(masterPath, 'centralRepo'))\n",
    "sys.path.insert(1, '../centralRepo')\n",
    "from eegDataset import eegDataset\n",
    "from baseModel import baseModel\n",
    "from networks import *\n",
    "import transforms\n",
    "from saveData import fetchData\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['modelArguments'] = {'nChan': 22, 'nTime': 1000, 'dropoutP': 0.5,\n",
    "                                    'nBands':9, 'm' : 32, 'temporalLayer': 'LogVarLayer',\n",
    "                                    'nClass': 4, 'doWeightNorm': True}\n",
    "\n",
    "# Training related details    \n",
    "config['modelTrainArguments'] = {'stopCondi':  {'c': {'Or': {'c1': {'MaxEpoch': {'maxEpochs': 1000, 'varName' : 'epoch'}},\n",
    "                                                   'c2': {'NoDecrease': {'numEpochs' : 200, 'varName': 'valInacc'}} } }},\n",
    "      'classes': [0,1], 'sampler' : 'RandomSampler', 'loadBestModel': True,\n",
    "      'bestVarToCheck': 'valInacc', 'continueAfterEarlystop':False,'lr': 1e-3}\n",
    "\n",
    "config['batchSize'] = 16\n",
    "nGPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['inDataPath'] = '../../data/bci42a/multiviewPython'\n",
    "config['inLabelPath'] = '../../data//bci42a/multiviewPython/dataLabels.csv'\n",
    "fbcnet_dataset = eegDataset(dataPath = config['inDataPath'], dataLabelsPath= config['inLabelPath'], preloadData = False, transform= None)\n",
    "FBCNET_ROOT_PATH = '../../output/bci42a/ses2Test/fbcnet_loso_finetune/'\n",
    "fbcnet = FBCNet(**config['modelArguments'])\n",
    "\n",
    "config['inDataPath'] = '../../data/bci42a/rawPython'\n",
    "config['inLabelPath'] = '../../data//bci42a/rawPython/dataLabels.csv'\n",
    "eegnet_dataset = eegDataset(dataPath = config['inDataPath'], dataLabelsPath= config['inLabelPath'], preloadData = False, transform= None)\n",
    "EEGNET_ROOT_PATH = '../../output/bci42a/ses2Test/eegnet_loso_finetune/'\n",
    "eegnet = eegNet(**config['modelArguments'])\n",
    "\n",
    "config['inDataPath'] = '../../data/bci42a/rawPython'\n",
    "config['inLabelPath'] = '../../data//bci42a/rawPython/dataLabels.csv'\n",
    "DEEPCONVNET_ROOT_PATH = '../../output/bci42a/ses2Test/deepconvnet_loso_finetune/'\n",
    "deepconvnet = deepConvNet(**config['modelArguments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_sub, data, model, session='1'):\n",
    "        subIdxTest = [i for i, x in enumerate(data.labels) if x[3] in test_sub and x[4] == session]\n",
    "        testData = copy.deepcopy(data)\n",
    "        testData.createPartialDataset(subIdxTest, loadNonLoadedData = True)\n",
    "\n",
    "        testResults, pred, act, pred_prob = model.test_preds(testData)\n",
    "\n",
    "        del testData\n",
    "        gc.collect()\n",
    "\n",
    "        return testResults, pred, act, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing subject 001 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model fbcnet {'acc': 0.7638888888888888, 'cm': array([[55, 11,  2,  4],\n",
      "       [ 4, 68,  0,  0],\n",
      "       [ 6,  4, 32, 30],\n",
      "       [ 0,  0,  7, 65]]), 'loss': 0.5886249012417264}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model eegnet {'acc': 0.7916666666666666, 'cm': array([[54, 11,  3,  4],\n",
      "       [ 9, 63,  0,  0],\n",
      "       [ 3,  0, 54, 15],\n",
      "       [ 4,  0, 11, 57]]), 'loss': 0.5459111001756456}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model deepconvnet {'acc': 0.7118055555555556, 'cm': array([[39, 26,  0,  7],\n",
      "       [ 8, 62,  2,  0],\n",
      "       [ 5,  5, 43, 19],\n",
      "       [ 2,  0,  9, 61]]), 'loss': 0.6884242163764106}\n",
      "Theoretical max accuracy: 0.9583333333333334\n",
      "Testing subject 002 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model fbcnet {'acc': 0.4652777777777778, 'cm': array([[27, 14, 29,  2],\n",
      "       [20, 21, 28,  3],\n",
      "       [ 1,  0, 71,  0],\n",
      "       [18, 20, 19, 15]]), 'loss': 1.3437745836046007}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model eegnet {'acc': 0.5659722222222222, 'cm': array([[40, 12, 13,  7],\n",
      "       [13, 39, 12,  8],\n",
      "       [11,  9, 52,  0],\n",
      "       [11, 16, 13, 32]]), 'loss': 1.1921287112765842}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model deepconvnet {'acc': 0.5451388888888888, 'cm': array([[47,  7, 11,  7],\n",
      "       [23, 29,  9, 11],\n",
      "       [16,  6, 49,  1],\n",
      "       [15, 16,  9, 32]]), 'loss': 1.0836476220024958}\n",
      "Theoretical max accuracy: 0.8194444444444444\n",
      "Testing subject 003 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model fbcnet {'acc': 0.8125, 'cm': array([[51,  4, 10,  7],\n",
      "       [ 4, 66,  0,  2],\n",
      "       [ 3,  4, 55, 10],\n",
      "       [ 2,  0,  8, 62]]), 'loss': 0.46485349867078996}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model eegnet {'acc': 0.5763888888888888, 'cm': array([[71,  1,  0,  0],\n",
      "       [34, 38,  0,  0],\n",
      "       [45,  0, 27,  0],\n",
      "       [41,  1,  0, 30]]), 'loss': 1.3771016862657335}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model deepconvnet {'acc': 0.8611111111111112, 'cm': array([[59,  4,  4,  5],\n",
      "       [ 6, 64,  2,  0],\n",
      "       [ 1,  4, 65,  2],\n",
      "       [ 3,  5,  4, 60]]), 'loss': 0.37457635667588973}\n",
      "Theoretical max accuracy: 0.9791666666666666\n",
      "Testing subject 004 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model fbcnet {'acc': 0.6666666666666666, 'cm': array([[47, 14,  8,  3],\n",
      "       [ 9, 56,  3,  4],\n",
      "       [ 6,  5, 46, 15],\n",
      "       [ 5, 20,  4, 43]]), 'loss': 0.8801651530795627}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model eegnet {'acc': 0.6805555555555556, 'cm': array([[56,  6,  6,  4],\n",
      "       [ 8, 48, 10,  6],\n",
      "       [10,  7, 46,  9],\n",
      "       [ 5,  9, 12, 46]]), 'loss': 0.8331993420918783}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model deepconvnet {'acc': 0.6319444444444444, 'cm': array([[44, 17,  6,  5],\n",
      "       [ 6, 57,  5,  4],\n",
      "       [ 8, 12, 43,  9],\n",
      "       [ 4, 22,  8, 38]]), 'loss': 0.9304634730021158}\n",
      "Theoretical max accuracy: 0.9201388888888888\n",
      "Testing subject 005 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model fbcnet {'acc': 0.5416666666666666, 'cm': array([[33, 28,  6,  5],\n",
      "       [ 6, 64,  2,  0],\n",
      "       [12, 29, 23,  8],\n",
      "       [ 9, 18,  9, 36]]), 'loss': 1.100246959262424}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model eegnet {'acc': 0.3958333333333333, 'cm': array([[ 4,  1,  4, 63],\n",
      "       [ 0,  4,  6, 62],\n",
      "       [ 0,  1, 34, 37],\n",
      "       [ 0,  0,  0, 72]]), 'loss': 2.7411604987250433}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model deepconvnet {'acc': 0.5833333333333334, 'cm': array([[55,  1,  0, 16],\n",
      "       [ 5, 26,  6, 35],\n",
      "       [11,  3, 29, 29],\n",
      "       [11,  2,  1, 58]]), 'loss': 0.9354980256822374}\n",
      "Theoretical max accuracy: 0.8854166666666666\n",
      "Testing subject 006 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model fbcnet {'acc': 0.5243055555555556, 'cm': array([[55,  2, 10,  5],\n",
      "       [34, 25,  6,  7],\n",
      "       [17,  4, 43,  8],\n",
      "       [24, 16,  4, 28]]), 'loss': 1.1813302569919162}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model eegnet {'acc': 0.6145833333333334, 'cm': array([[61,  2,  3,  6],\n",
      "       [13, 39,  4, 16],\n",
      "       [13,  7, 41, 11],\n",
      "       [12, 13, 11, 36]]), 'loss': 1.1375145382351346}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model deepconvnet {'acc': 0.5590277777777778, 'cm': array([[45, 10,  4, 13],\n",
      "       [ 9, 35, 10, 18],\n",
      "       [10, 14, 31, 17],\n",
      "       [ 7, 11,  4, 50]]), 'loss': 1.0688977771335177}\n",
      "Theoretical max accuracy: 0.8645833333333334\n",
      "Testing subject 007 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model fbcnet {'acc': 0.6909722222222222, 'cm': array([[35,  7,  6, 24],\n",
      "       [ 6, 44,  3, 19],\n",
      "       [ 0,  0, 54, 18],\n",
      "       [ 0,  1,  5, 66]]), 'loss': 0.7833568255106608}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model eegnet {'acc': 0.7638888888888888, 'cm': array([[49,  2, 12,  9],\n",
      "       [ 2, 53,  5, 12],\n",
      "       [ 3,  8, 56,  5],\n",
      "       [ 2,  6,  2, 62]]), 'loss': 0.6773707071940104}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model deepconvnet {'acc': 0.7534722222222222, 'cm': array([[41,  5, 21,  5],\n",
      "       [ 2, 53, 13,  4],\n",
      "       [ 1,  7, 62,  2],\n",
      "       [ 3,  4,  4, 61]]), 'loss': 0.6750373840332031}\n",
      "Theoretical max accuracy: 0.9583333333333334\n",
      "Testing subject 008 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model fbcnet {'acc': 0.7847222222222222, 'cm': array([[64,  3,  5,  0],\n",
      "       [ 0, 66,  3,  3],\n",
      "       [10,  8, 47,  7],\n",
      "       [ 9, 11,  3, 49]]), 'loss': 0.6651807361178927}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model eegnet {'acc': 0.7430555555555556, 'cm': array([[64,  1,  6,  1],\n",
      "       [ 1, 64,  6,  1],\n",
      "       [ 6, 11, 54,  1],\n",
      "       [ 9, 21, 10, 32]]), 'loss': 0.8470720714992948}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model deepconvnet {'acc': 0.7638888888888888, 'cm': array([[62,  0,  8,  2],\n",
      "       [ 1, 65,  5,  1],\n",
      "       [ 6, 11, 53,  2],\n",
      "       [ 9, 12, 11, 40]]), 'loss': 0.5691843032836914}\n",
      "Theoretical max accuracy: 0.9340277777777778\n",
      "Testing subject 009 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model fbcnet {'acc': 0.7777777777777778, 'cm': array([[68,  3,  1,  0],\n",
      "       [ 7, 45,  8, 12],\n",
      "       [ 4, 10, 46, 12],\n",
      "       [ 0,  5,  2, 65]]), 'loss': 0.6311166551378038}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model eegnet {'acc': 0.7083333333333334, 'cm': array([[66,  2,  3,  1],\n",
      "       [ 1, 47, 23,  1],\n",
      "       [ 4, 16, 44,  8],\n",
      "       [ 6,  4, 15, 47]]), 'loss': 0.7501369052463107}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model deepconvnet {'acc': 0.625, 'cm': array([[68,  4,  0,  0],\n",
      "       [ 4, 44, 24,  0],\n",
      "       [ 9, 18, 39,  6],\n",
      "       [10, 12, 21, 29]]), 'loss': 0.9070219463772244}\n",
      "Theoretical max accuracy: 0.8993055555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    }
   ],
   "source": [
    "subs = list(range(9))\n",
    "accs = []\n",
    "all_preds = {}\n",
    "all_pred_probs = {}\n",
    "all_losses = {}\n",
    "all_test_results = {}\n",
    "all_acts = {}\n",
    "all_train_preds = {}\n",
    "all_train_pred_probs = {}\n",
    "all_train_losses = {}\n",
    "all_train_results = {}\n",
    "models = ['fbcnet', 'eegnet', 'deepconvnet']\n",
    "datasets = [fbcnet_dataset, eegnet_dataset, eegnet_dataset]\n",
    "networks = [fbcnet, eegnet, deepconvnet]\n",
    "ROOTS = [FBCNET_ROOT_PATH, EEGNET_ROOT_PATH, DEEPCONVNET_ROOT_PATH]\n",
    "# models = ['fbcnet', 'deepconvnet']\n",
    "# datasets = [fbcnet_dataset, eegnet_dataset]\n",
    "# networks = [fbcnet, deepconvnet]\n",
    "# ROOTS = [FBCNET_ROOT_PATH, DEEPCONVNET_ROOT_PATH]\n",
    "for test_sub in subs:\n",
    "    test_sub_str = '00' + str(test_sub + 1)\n",
    "    preds = []\n",
    "    pred_probs = []\n",
    "    train_preds = []\n",
    "    train_pred_probs = []\n",
    "    results = {}\n",
    "    train_results = {}\n",
    "    train_losses = []\n",
    "    print(\"Testing subject \" + test_sub_str + \" with all models...\")\n",
    "    for i, (net, ROOT_PATH) in enumerate(zip(networks, ROOTS)):\n",
    "        state_dict_path = os.path.join(ROOT_PATH, 'finetuned_sub' + test_sub_str, 'network_state_dict.pth')\n",
    "        netInitState = torch.load(state_dict_path)\n",
    "        net.load_state_dict(netInitState, strict=False)\n",
    "        outPathSub = None\n",
    "        model = baseModel(net=net, resultsSavePath=outPathSub, batchSize= config['batchSize'], nGPU = nGPU)\n",
    "        testResults, pred, act, pred_prob = test_model(test_sub_str, datasets[i], model, session='0')\n",
    "        train_preds.append(pred)\n",
    "        train_pred_probs.append(pred_prob)\n",
    "        train_results[models[i]] = testResults\n",
    "        train_losses.append(testResults['loss'])\n",
    "\n",
    "        testResults, pred, act, pred_prob = test_model(test_sub_str, datasets[i], model)\n",
    "        preds.append(pred)\n",
    "        pred_probs.append(pred_prob)\n",
    "        results[models[i]] = testResults\n",
    "        print(\"Results for model\", models[i], testResults)\n",
    "    \n",
    "    correct = 0\n",
    "    for i in range(len(act)):\n",
    "        for pred in preds:\n",
    "            if(pred[i] == act[i]):\n",
    "                correct += 1\n",
    "                break\n",
    "    \n",
    "    all_preds[test_sub] = preds\n",
    "    all_pred_probs[test_sub] = pred_probs\n",
    "    all_acts[test_sub] = act\n",
    "    all_test_results[test_sub] = results\n",
    "    \n",
    "    all_train_preds[test_sub] = train_preds\n",
    "    all_train_pred_probs[test_sub] = train_pred_probs\n",
    "    all_train_losses[test_sub] = train_losses\n",
    "    all_train_results[test_sub] = train_results\n",
    "    \n",
    "    acc = correct/len(act)\n",
    "    accs.append(acc)\n",
    "    print(\"Theoretical max accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9583333333333334,\n",
       " 0.8194444444444444,\n",
       " 0.9791666666666666,\n",
       " 0.9201388888888888,\n",
       " 0.8854166666666666,\n",
       " 0.8645833333333334,\n",
       " 0.9583333333333334,\n",
       " 0.9340277777777778,\n",
       " 0.8993055555555556]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average theoretical max accuracy: 0.9131944444444444\n"
     ]
    }
   ],
   "source": [
    "avg_acc = sum(accs) / len(accs)\n",
    "print(\"Average theoretical max accuracy:\", avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.833 & 81.944 & 97.917 & 92.014 & 88.542 & 86.458 & 95.833 & 93.403 & 89.931 & 91.319\n"
     ]
    }
   ],
   "source": [
    "accs.append(avg_acc)\n",
    "tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voted accuracy: 0.8020833333333334\n",
      "Voted accuracy: 0.5972222222222222\n",
      "Voted accuracy: 0.8229166666666666\n",
      "Voted accuracy: 0.7118055555555556\n",
      "Voted accuracy: 0.5902777777777778\n",
      "Voted accuracy: 0.6111111111111112\n",
      "Voted accuracy: 0.8159722222222222\n",
      "Voted accuracy: 0.8125\n",
      "Voted accuracy: 0.7256944444444444\n",
      "Average voted accuracy: 0.7210648148148148\n",
      "Median voted accuracy: 0.7256944444444444\n",
      "80.208 & 59.722 & 82.292 & 71.181 & 59.028 & 61.111 & 81.597 & 81.250 & 72.569 & 72.106\n"
     ]
    }
   ],
   "source": [
    "voted_accs = []\n",
    "for test_sub in subs:\n",
    "    voted_pred = []\n",
    "#     test_sub = 1\n",
    "    preds = all_preds[test_sub]\n",
    "    act = all_acts[test_sub]\n",
    "    for i in range(len(preds[0])):\n",
    "        votes = {l:0 for l in range(4)}\n",
    "        for pred in preds:\n",
    "            votes[pred[i]]+=1\n",
    "        voted_pred.append(max(votes, key=votes.get))\n",
    "\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(voted_pred, act):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(act)\n",
    "    voted_accs.append(voted_acc)\n",
    "    print(\"Voted accuracy:\", voted_acc)\n",
    "    \n",
    "avg_voted_acc = sum(voted_accs) / len(voted_accs)\n",
    "print(\"Average voted accuracy:\", avg_voted_acc)\n",
    "print(\"Median voted accuracy:\", statistics.median(voted_accs))\n",
    "voted_accs.append(avg_voted_acc)\n",
    "tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in voted_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft probability combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft probability combined accuracy: 0.8263888888888888\n",
      "Soft probability combined accuracy: 0.625\n",
      "Soft probability combined accuracy: 0.8715277777777778\n",
      "Soft probability combined accuracy: 0.7604166666666666\n",
      "Soft probability combined accuracy: 0.4722222222222222\n",
      "Soft probability combined accuracy: 0.6770833333333334\n",
      "Soft probability combined accuracy: 0.8368055555555556\n",
      "Soft probability combined accuracy: 0.8055555555555556\n",
      "Soft probability combined accuracy: 0.7604166666666666\n",
      "Average combined accuracy: 0.7372685185185185\n",
      "Median combined accuracy: 0.7604166666666666\n",
      "82.639 \n",
      "62.500 \n",
      "87.153 \n",
      "76.042 \n",
      "47.222 \n",
      "67.708 \n",
      "83.681 \n",
      "80.556 \n",
      "76.042 \n",
      "73.727\n"
     ]
    }
   ],
   "source": [
    "comb_accs = []\n",
    "for test_sub in subs:\n",
    "    pred_probs = np.array(all_pred_probs[test_sub])\n",
    "    n, h, w, c = pred_probs.shape\n",
    "    pred_probs = np.reshape(pred_probs, (n, h*w, c))\n",
    "    class_probs = np.sum(pred_probs, axis=0)\n",
    "    soft_preds = np.argmax(class_probs, axis=1)\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(soft_preds, all_acts[test_sub]):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(all_acts[test_sub])\n",
    "    comb_accs.append(voted_acc)\n",
    "    print(\"Soft probability combined accuracy:\", voted_acc)\n",
    "\n",
    "avg_comb_acc = sum(comb_accs) / len(comb_accs)\n",
    "print(\"Average combined accuracy:\", avg_comb_acc)\n",
    "print(\"Median combined accuracy:\", statistics.median(comb_accs))\n",
    "comb_accs.append(avg_comb_acc)\n",
    "tabstr = ' \\n'.join([\"{0:.3f}\".format(x*100) for x in comb_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {test_sub: {train_sub: results['cm'] for train_sub, results in test_results.items()} for test_sub, test_results in all_train_results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {test_sub: {train_sub: np.array([cm[i][i]/np.sum(cm[i,:]) for i in range(4)]) for train_sub, cm in test_results.items()} for test_sub, test_results in cms.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_sums = {test_sub: np.array([np.sum(recalls) for train_sub, recalls in test_results.items()]) for test_sub, test_results in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.90277778, 4.        , 4.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_sums[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(recall_sums[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft probability combined accuracy: 0.8263888888888888\n",
      "Soft probability combined accuracy: 0.625\n",
      "Soft probability combined accuracy: 0.9375\n",
      "Soft probability combined accuracy: 0.7604166666666666\n",
      "Soft probability combined accuracy: 0.4722222222222222\n",
      "Soft probability combined accuracy: 0.6736111111111112\n",
      "Soft probability combined accuracy: 0.8368055555555556\n",
      "Soft probability combined accuracy: 0.8055555555555556\n",
      "Soft probability combined accuracy: 0.7638888888888888\n",
      "Average combined accuracy: 0.7445987654320988\n",
      "Median combined accuracy: 0.7638888888888888\n",
      "82.639\n",
      "62.500\n",
      "93.750\n",
      "76.042\n",
      "47.222\n",
      "67.361\n",
      "83.681\n",
      "80.556\n",
      "76.389\n",
      "74.460\n"
     ]
    }
   ],
   "source": [
    "comb_accs = []\n",
    "for test_sub in subs:\n",
    "    pred_probs = np.array(all_pred_probs[test_sub])\n",
    "    n, h, w, c = pred_probs.shape\n",
    "    pred_probs = np.reshape(pred_probs, (n, h*w, c))\n",
    "#     print(pred_probs)\n",
    "    for i in range(len(pred_probs)):\n",
    "#         print(pred_probs[i])\n",
    "        for j in range(len(pred_probs[i])):\n",
    "            pred_probs[i][j] = np.multiply(pred_probs[i][j], metrics[test_sub][models[i]])\n",
    "    class_probs = np.sum(pred_probs, axis=0)\n",
    "    soft_preds = np.argmax(class_probs, axis=1)\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(soft_preds, all_acts[test_sub]):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(all_acts[test_sub])\n",
    "    comb_accs.append(voted_acc)\n",
    "    print(\"Soft probability combined accuracy:\", voted_acc)\n",
    "\n",
    "avg_comb_acc = sum(comb_accs) / len(comb_accs)\n",
    "print(\"Average combined accuracy:\", avg_comb_acc)\n",
    "print(\"Median combined accuracy:\", statistics.median(comb_accs))\n",
    "comb_accs.append(avg_comb_acc)\n",
    "tabstr = '\\n'.join([\"{0:.3f}\".format(x*100) for x in comb_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voted accuracy: 0.8020833333333334\n",
      "Voted accuracy: 0.5798611111111112\n",
      "Voted accuracy: 0.8229166666666666\n",
      "Voted accuracy: 0.7118055555555556\n",
      "Voted accuracy: 0.5902777777777778\n",
      "Voted accuracy: 0.6180555555555556\n",
      "Voted accuracy: 0.8159722222222222\n",
      "Voted accuracy: 0.8125\n",
      "Voted accuracy: 0.7256944444444444\n",
      "Average voted accuracy: 0.7199074074074074\n",
      "Median voted accuracy: 0.7256944444444444\n",
      "80.208 & 57.986 & 82.292 & 71.181 & 59.028 & 61.806 & 81.597 & 81.250 & 72.569 & 71.991\n"
     ]
    }
   ],
   "source": [
    "voted_accs = []\n",
    "for test_sub in subs:\n",
    "    voted_pred = []\n",
    "#     test_sub = 1\n",
    "    preds = all_preds[test_sub]\n",
    "    act = all_acts[test_sub]\n",
    "    for i in range(len(preds[0])):\n",
    "        votes = {l:0 for l in range(4)}\n",
    "        for j, pred in enumerate(preds):\n",
    "            votes[pred[i]]+=metrics[test_sub][models[j]][pred[i]]\n",
    "        voted_pred.append(max(votes, key=votes.get))\n",
    "\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(voted_pred, act):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(act)\n",
    "    voted_accs.append(voted_acc)\n",
    "    print(\"Voted accuracy:\", voted_acc)\n",
    "    \n",
    "avg_voted_acc = sum(voted_accs) / len(voted_accs)\n",
    "print(\"Average voted accuracy:\", avg_voted_acc)\n",
    "print(\"Median voted accuracy:\", statistics.median(voted_accs))\n",
    "voted_accs.append(avg_voted_acc)\n",
    "tabstr = ' & '.join([\"{0:.3f}\".format(x*100) for x in voted_accs])\n",
    "print(tabstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
