{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import xlwt\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# masterPath = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# sys.path.insert(1, os.path.join(masterPath, 'centralRepo'))\n",
    "sys.path.insert(1, '../centralRepo')\n",
    "from eegDataset import eegDataset\n",
    "from baseModel import baseModel\n",
    "from networks import *\n",
    "import transforms\n",
    "from saveData import fetchData\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['modelArguments'] = {'nChan': 22, 'nTime': 1000, 'dropoutP': 0.5,\n",
    "                                    'nBands':9, 'm' : 32, 'temporalLayer': 'LogVarLayer',\n",
    "                                    'nClass': 4, 'doWeightNorm': True}\n",
    "\n",
    "# Training related details    \n",
    "config['modelTrainArguments'] = {'stopCondi':  {'c': {'Or': {'c1': {'MaxEpoch': {'maxEpochs': 1000, 'varName' : 'epoch'}},\n",
    "                                                   'c2': {'NoDecrease': {'numEpochs' : 200, 'varName': 'valInacc'}} } }},\n",
    "      'classes': [0,1], 'sampler' : 'RandomSampler', 'loadBestModel': True,\n",
    "      'bestVarToCheck': 'valInacc', 'continueAfterEarlystop':False,'lr': 1e-3}\n",
    "\n",
    "config['batchSize'] = 16\n",
    "nGPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['inDataPath'] = '../../data/bci42a/multiviewPython'\n",
    "config['inLabelPath'] = '../../data//bci42a/multiviewPython/dataLabels.csv'\n",
    "ROOT_PATH = '../../output/bci42a/ses2Test/fbcnet_cross_subs/'\n",
    "net = FBCNet(**config['modelArguments'])\n",
    "\n",
    "# config['inDataPath'] = '../../data/bci42a/rawPython'\n",
    "# config['inLabelPath'] = '../../data//bci42a/rawPython/dataLabels.csv'\n",
    "# ROOT_PATH = '../../output/bci42a/ses2Test/eegnet_cross_subject/'\n",
    "# net = eegNet(**config['modelArguments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = eegDataset(dataPath = config['inDataPath'], dataLabelsPath= config['inLabelPath'], preloadData = False, transform= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_sub, data, model, session='1'):\n",
    "        subIdxTest = [i for i, x in enumerate(data.labels) if x[3] in test_sub and x[4] == session]\n",
    "        testData = copy.deepcopy(data)\n",
    "        testData.createPartialDataset(subIdxTest, loadNonLoadedData = True)\n",
    "\n",
    "        testResults, pred, act, pred_prob = model.test_preds(testData)\n",
    "\n",
    "        del testData\n",
    "        gc.collect()\n",
    "\n",
    "        return testResults, pred, act, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing subject 001 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.8472222222222222, 'cm': array([[64,  2,  3,  3],\n",
      "       [ 7, 64,  1,  0],\n",
      "       [ 0,  0, 58, 14],\n",
      "       [ 0,  0, 14, 58]]), 'loss': 0.3926004303826226}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.7048611111111112, 'cm': array([[51,  9, 11,  1],\n",
      "       [21, 45,  6,  0],\n",
      "       [ 1,  0, 54, 17],\n",
      "       [ 0,  0, 19, 53]]), 'loss': 0.6606802940368652}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.6909722222222222, 'cm': array([[41, 15, 10,  6],\n",
      "       [ 8, 61,  3,  0],\n",
      "       [ 1,  0, 45, 26],\n",
      "       [ 0,  0, 20, 52]]), 'loss': 0.6937871509128146}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.7465277777777778, 'cm': array([[58,  4,  9,  1],\n",
      "       [12, 56,  4,  0],\n",
      "       [ 2,  1, 59, 10],\n",
      "       [ 1,  0, 29, 42]]), 'loss': 0.6049310896131728}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.6666666666666666, 'cm': array([[51,  7,  8,  6],\n",
      "       [20, 43,  9,  0],\n",
      "       [ 2,  0, 37, 33],\n",
      "       [ 0,  0, 11, 61]]), 'loss': 0.6990844938490126}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.6006944444444444, 'cm': array([[64,  1,  6,  1],\n",
      "       [45, 18,  9,  0],\n",
      "       [ 5,  0, 42, 25],\n",
      "       [ 0,  0, 23, 49]]), 'loss': 0.742124080657959}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.7430555555555556, 'cm': array([[59,  2,  6,  5],\n",
      "       [24, 44,  4,  0],\n",
      "       [ 1,  0, 65,  6],\n",
      "       [ 0,  0, 26, 46]]), 'loss': 0.6115825441148546}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.6354166666666666, 'cm': array([[62,  1,  9,  0],\n",
      "       [38, 23, 11,  0],\n",
      "       [ 2,  0, 58, 12],\n",
      "       [ 0,  0, 32, 40]]), 'loss': 0.7668737835354276}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.7465277777777778, 'cm': array([[60,  5,  5,  2],\n",
      "       [13, 52,  7,  0],\n",
      "       [ 5,  0, 55, 12],\n",
      "       [ 1,  0, 23, 48]]), 'loss': 0.5870521863301595}\n",
      "Theoretical max accuracy: 0.9791666666666666\n",
      "Testing subject 002 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.4583333333333333, 'cm': array([[19, 26, 24,  3],\n",
      "       [ 6, 40, 16, 10],\n",
      "       [ 2,  6, 64,  0],\n",
      "       [14, 24, 25,  9]]), 'loss': 1.26515441470676}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.5729166666666666, 'cm': array([[37, 11, 17,  7],\n",
      "       [27, 29, 10,  6],\n",
      "       [ 0,  0, 69,  3],\n",
      "       [24, 12,  6, 30]]), 'loss': 0.9677812788221571}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.4965277777777778, 'cm': array([[35,  3, 30,  4],\n",
      "       [19, 16, 31,  6],\n",
      "       [ 1,  0, 69,  2],\n",
      "       [18,  9, 22, 23]]), 'loss': 1.2325933244493272}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.4583333333333333, 'cm': array([[26, 24, 15,  7],\n",
      "       [22, 34, 12,  4],\n",
      "       [ 4,  5, 63,  0],\n",
      "       [22, 29, 12,  9]]), 'loss': 1.1804112328423395}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.4375, 'cm': array([[24, 30, 16,  2],\n",
      "       [19, 36, 11,  6],\n",
      "       [ 6, 12, 52,  2],\n",
      "       [20, 25, 13, 14]]), 'loss': 1.2247094048394098}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.4652777777777778, 'cm': array([[10,  8, 30, 24],\n",
      "       [10, 15, 23, 24],\n",
      "       [ 1,  2, 68,  1],\n",
      "       [ 8,  9, 14, 41]]), 'loss': 1.2528582678900824}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.5034722222222222, 'cm': array([[42, 11, 14,  5],\n",
      "       [31, 25, 10,  6],\n",
      "       [ 4,  3, 62,  3],\n",
      "       [34, 14,  8, 16]]), 'loss': 1.1183867984347873}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.5, 'cm': array([[28, 29, 12,  3],\n",
      "       [16, 43,  7,  6],\n",
      "       [ 5,  4, 60,  3],\n",
      "       [23, 29,  7, 13]]), 'loss': 1.172980096605089}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.4756944444444444, 'cm': array([[30, 26, 13,  3],\n",
      "       [30, 32,  6,  4],\n",
      "       [ 7,  4, 60,  1],\n",
      "       [24, 24,  9, 15]]), 'loss': 1.1395355860392253}\n",
      "Theoretical max accuracy: 0.8472222222222222\n",
      "Testing subject 003 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.8229166666666666, 'cm': array([[52,  8,  3,  9],\n",
      "       [ 0, 70,  0,  2],\n",
      "       [ 0,  5, 49, 18],\n",
      "       [ 1,  1,  4, 66]]), 'loss': 0.4898236592610677}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.7881944444444444, 'cm': array([[62,  7,  3,  0],\n",
      "       [ 3, 69,  0,  0],\n",
      "       [ 8, 13, 44,  7],\n",
      "       [ 6,  2, 12, 52]]), 'loss': 0.581877867380778}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.9027777777777778, 'cm': array([[65,  6,  0,  1],\n",
      "       [ 0, 72,  0,  0],\n",
      "       [ 1,  6, 60,  5],\n",
      "       [ 2,  2,  5, 63]]), 'loss': 0.24447446399264866}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.8229166666666666, 'cm': array([[64,  2,  5,  1],\n",
      "       [ 2, 66,  3,  1],\n",
      "       [ 6,  4, 45, 17],\n",
      "       [ 5,  1,  4, 62]]), 'loss': 0.5377021895514594}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.7777777777777778, 'cm': array([[54, 12,  4,  2],\n",
      "       [ 1, 69,  1,  1],\n",
      "       [ 4, 17, 36, 15],\n",
      "       [ 5,  1,  1, 65]]), 'loss': 0.6016759342617459}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.78125, 'cm': array([[55,  1, 11,  5],\n",
      "       [ 9, 51,  9,  3],\n",
      "       [ 3,  1, 53, 15],\n",
      "       [ 1,  0,  5, 66]]), 'loss': 0.6244690153333876}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.7847222222222222, 'cm': array([[59, 11,  1,  1],\n",
      "       [ 2, 70,  0,  0],\n",
      "       [ 9, 11, 49,  3],\n",
      "       [ 9,  3, 12, 48]]), 'loss': 0.6138793627421061}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.7361111111111112, 'cm': array([[57,  7,  0,  8],\n",
      "       [ 8, 59,  0,  5],\n",
      "       [ 7, 11, 26, 28],\n",
      "       [ 0,  1,  1, 70]]), 'loss': 0.6888613171047635}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.8229166666666666, 'cm': array([[69,  3,  0,  0],\n",
      "       [ 2, 68,  2,  0],\n",
      "       [ 6, 11, 43, 12],\n",
      "       [ 3,  1, 11, 57]]), 'loss': 0.492451720767551}\n",
      "Theoretical max accuracy: 0.9895833333333334\n",
      "Testing subject 004 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.5451388888888888, 'cm': array([[37, 30,  0,  5],\n",
      "       [ 7, 61,  0,  4],\n",
      "       [ 9, 18, 16, 29],\n",
      "       [ 6, 23,  0, 43]]), 'loss': 1.0261107550726996}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.6770833333333334, 'cm': array([[50, 12,  8,  2],\n",
      "       [12, 46, 10,  4],\n",
      "       [ 4,  3, 55, 10],\n",
      "       [ 6,  8, 14, 44]]), 'loss': 0.9313543107774522}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.5208333333333334, 'cm': array([[55, 12,  1,  4],\n",
      "       [21, 47,  1,  3],\n",
      "       [27, 14, 19, 12],\n",
      "       [22, 20,  1, 29]]), 'loss': 1.1056012047661676}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.8090277777777778, 'cm': array([[56,  9,  5,  2],\n",
      "       [ 2, 61,  7,  2],\n",
      "       [ 3,  1, 60,  8],\n",
      "       [ 5,  3,  8, 56]]), 'loss': 0.6794248157077365}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.6006944444444444, 'cm': array([[52, 15,  1,  4],\n",
      "       [19, 41,  4,  8],\n",
      "       [ 5, 11, 32, 24],\n",
      "       [ 7, 12,  5, 48]]), 'loss': 0.9371049669053819}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.5625, 'cm': array([[60,  5,  4,  3],\n",
      "       [36, 28,  7,  1],\n",
      "       [14,  4, 41, 13],\n",
      "       [18,  8, 13, 33]]), 'loss': 0.990947405497233}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.6354166666666666, 'cm': array([[63,  5,  1,  3],\n",
      "       [22, 41,  2,  7],\n",
      "       [13,  7, 32, 20],\n",
      "       [12, 10,  3, 47]]), 'loss': 0.9155874252319336}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.5381944444444444, 'cm': array([[42,  8, 19,  3],\n",
      "       [15, 29, 20,  8],\n",
      "       [ 6,  3, 40, 23],\n",
      "       [11,  2, 15, 44]]), 'loss': 1.0440571043226454}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.5416666666666666, 'cm': array([[34, 24,  6,  8],\n",
      "       [16, 41,  7,  8],\n",
      "       [ 5,  7, 26, 34],\n",
      "       [ 3, 12,  2, 55]]), 'loss': 1.0457563400268555}\n",
      "Theoretical max accuracy: 0.9791666666666666\n",
      "Testing subject 005 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.4444444444444444, 'cm': array([[23, 30, 18,  1],\n",
      "       [ 1, 69,  1,  1],\n",
      "       [ 9, 38, 24,  1],\n",
      "       [ 3, 33, 24, 12]]), 'loss': 1.267695215013292}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.53125, 'cm': array([[22, 24, 10, 16],\n",
      "       [ 7, 50,  4, 11],\n",
      "       [ 5, 21, 28, 18],\n",
      "       [ 3, 12,  4, 53]]), 'loss': 1.099339485168457}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.5243055555555556, 'cm': array([[58, 12,  0,  2],\n",
      "       [26, 42,  0,  4],\n",
      "       [32, 15, 13, 12],\n",
      "       [25,  7,  2, 38]]), 'loss': 1.1250243716769748}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.5243055555555556, 'cm': array([[31,  2, 17, 22],\n",
      "       [19, 17, 10, 26],\n",
      "       [ 9,  2, 45, 16],\n",
      "       [ 7,  0,  7, 58]]), 'loss': 1.157441669040256}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.7013888888888888, 'cm': array([[64,  4,  0,  4],\n",
      "       [ 4, 68,  0,  0],\n",
      "       [23, 15, 19, 15],\n",
      "       [13,  6,  2, 51]]), 'loss': 0.8453003565470377}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.4861111111111111, 'cm': array([[37,  3,  8, 24],\n",
      "       [21, 20,  8, 23],\n",
      "       [13,  1, 25, 33],\n",
      "       [ 9,  0,  5, 58]]), 'loss': 1.1339172787136502}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.5034722222222222, 'cm': array([[48,  2,  3, 19],\n",
      "       [18, 38,  2, 14],\n",
      "       [21,  6,  8, 37],\n",
      "       [14,  5,  2, 51]]), 'loss': 1.1408924526638455}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.4340277777777778, 'cm': array([[44,  5,  1, 22],\n",
      "       [30, 21,  0, 21],\n",
      "       [19,  3, 12, 38],\n",
      "       [14,  4,  6, 48]]), 'loss': 1.25010257297092}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.4340277777777778, 'cm': array([[70,  2,  0,  0],\n",
      "       [39, 29,  3,  1],\n",
      "       [52,  6, 12,  2],\n",
      "       [39, 10,  9, 14]]), 'loss': 1.3059506946139865}\n",
      "Theoretical max accuracy: 0.9513888888888888\n",
      "Testing subject 006 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.4270833333333333, 'cm': array([[49,  5,  5, 13],\n",
      "       [31, 19,  3, 19],\n",
      "       [20,  4, 18, 30],\n",
      "       [20, 12,  3, 37]]), 'loss': 1.2636160320705838}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.4826388888888889, 'cm': array([[45, 17,  9,  1],\n",
      "       [17, 45, 10,  0],\n",
      "       [16, 12, 41,  3],\n",
      "       [23, 27, 14,  8]]), 'loss': 1.332342677646213}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.4444444444444444, 'cm': array([[41, 20,  6,  5],\n",
      "       [22, 40,  4,  6],\n",
      "       [13, 16, 28, 15],\n",
      "       [21, 31,  1, 19]]), 'loss': 1.2030584547254775}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.4131944444444444, 'cm': array([[26, 32,  2, 12],\n",
      "       [10, 55,  0,  7],\n",
      "       [ 8, 28, 10, 26],\n",
      "       [11, 33,  0, 28]]), 'loss': 1.3188594182332356}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.4826388888888889, 'cm': array([[46, 10,  6, 10],\n",
      "       [22, 32,  5, 13],\n",
      "       [15,  9, 29, 19],\n",
      "       [25,  9,  6, 32]]), 'loss': 1.2166225645277235}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.5486111111111112, 'cm': array([[38, 17,  9,  8],\n",
      "       [16, 41,  7,  8],\n",
      "       [ 9, 11, 45,  7],\n",
      "       [13, 22,  3, 34]]), 'loss': 1.0409988827175565}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.3958333333333333, 'cm': array([[53, 11,  1,  7],\n",
      "       [41, 28,  2,  1],\n",
      "       [23, 21, 18, 10],\n",
      "       [29, 27,  1, 15]]), 'loss': 1.3235370847913954}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.4965277777777778, 'cm': array([[39, 12,  8, 13],\n",
      "       [18, 32, 10, 12],\n",
      "       [ 8,  8, 35, 21],\n",
      "       [12, 12, 11, 37]]), 'loss': 1.1979469723171658}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.4409722222222222, 'cm': array([[45, 13,  4, 10],\n",
      "       [30, 32,  4,  6],\n",
      "       [13, 12, 23, 24],\n",
      "       [20, 21,  4, 27]]), 'loss': 1.2582420772976346}\n",
      "Theoretical max accuracy: 0.8888888888888888\n",
      "Testing subject 007 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.7013888888888888, 'cm': array([[39, 14,  4, 15],\n",
      "       [ 4, 48, 11,  9],\n",
      "       [ 0,  2, 48, 22],\n",
      "       [ 0,  0,  5, 67]]), 'loss': 0.7824184629652235}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.5381944444444444, 'cm': array([[14, 18,  1, 39],\n",
      "       [ 2, 33,  1, 36],\n",
      "       [ 0,  0, 37, 35],\n",
      "       [ 1,  0,  0, 71]]), 'loss': 1.1220164828830295}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.6388888888888888, 'cm': array([[40, 13,  3, 16],\n",
      "       [16, 29,  7, 20],\n",
      "       [ 1,  2, 49, 20],\n",
      "       [ 0,  0,  6, 66]]), 'loss': 0.83221345477634}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.7118055555555556, 'cm': array([[45, 13,  1, 13],\n",
      "       [10, 52,  2,  8],\n",
      "       [ 2,  4, 40, 26],\n",
      "       [ 0,  2,  2, 68]]), 'loss': 0.7287325859069824}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.6666666666666666, 'cm': array([[32, 22,  2, 16],\n",
      "       [ 8, 55,  0,  9],\n",
      "       [ 0,  0, 37, 35],\n",
      "       [ 0,  1,  3, 68]]), 'loss': 0.7588997946845161}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.7083333333333334, 'cm': array([[27, 26,  2, 17],\n",
      "       [ 2, 59,  2,  9],\n",
      "       [ 2,  4, 48, 18],\n",
      "       [ 0,  1,  1, 70]]), 'loss': 0.7643464406331381}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.8229166666666666, 'cm': array([[49,  5,  0, 18],\n",
      "       [ 2, 66,  0,  4],\n",
      "       [ 0,  0, 53, 19],\n",
      "       [ 0,  0,  3, 69]]), 'loss': 0.40207386016845703}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.59375, 'cm': array([[19, 34,  3, 16],\n",
      "       [ 4, 48,  6, 14],\n",
      "       [ 2, 10, 43, 17],\n",
      "       [ 0,  7,  4, 61]]), 'loss': 0.9059296713935004}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.625, 'cm': array([[40, 16,  2, 14],\n",
      "       [10, 34,  7, 21],\n",
      "       [ 0,  2, 42, 28],\n",
      "       [ 1,  1,  6, 64]]), 'loss': 0.8559280501471626}\n",
      "Theoretical max accuracy: 0.9444444444444444\n",
      "Testing subject 008 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.6701388888888888, 'cm': array([[45,  1, 26,  0],\n",
      "       [ 0, 53, 18,  1],\n",
      "       [ 6,  3, 51, 12],\n",
      "       [ 4,  5, 19, 44]]), 'loss': 0.7709805170694987}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.6666666666666666, 'cm': array([[41,  1, 30,  0],\n",
      "       [ 0, 45, 24,  3],\n",
      "       [ 5,  2, 61,  4],\n",
      "       [ 5,  3, 19, 45]]), 'loss': 0.7551488346523709}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.7118055555555556, 'cm': array([[65,  1,  2,  4],\n",
      "       [ 2, 54,  5, 11],\n",
      "       [16,  7, 30, 19],\n",
      "       [10,  5,  1, 56]]), 'loss': 0.7382417784796821}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.6840277777777778, 'cm': array([[62,  6,  3,  1],\n",
      "       [ 0, 70,  0,  2],\n",
      "       [10, 31, 17, 14],\n",
      "       [ 5, 19,  0, 48]]), 'loss': 0.8141160541110568}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.7083333333333334, 'cm': array([[55,  2, 14,  1],\n",
      "       [ 2, 49, 17,  4],\n",
      "       [ 7,  2, 52, 11],\n",
      "       [ 7,  3, 14, 48]]), 'loss': 0.749795224931505}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.6423611111111112, 'cm': array([[56,  0, 16,  0],\n",
      "       [ 0, 51, 20,  1],\n",
      "       [12,  4, 53,  3],\n",
      "       [13,  8, 26, 25]]), 'loss': 0.8689548704359267}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.6666666666666666, 'cm': array([[69,  1,  2,  0],\n",
      "       [ 3, 63,  4,  2],\n",
      "       [32,  5, 26,  9],\n",
      "       [27,  6,  5, 34]]), 'loss': 0.8211832576327853}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.8090277777777778, 'cm': array([[66,  1,  5,  0],\n",
      "       [ 0, 66,  4,  2],\n",
      "       [ 6,  8, 53,  5],\n",
      "       [ 7, 12,  5, 48]]), 'loss': 0.5417526563008627}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.6944444444444444, 'cm': array([[64,  1,  7,  0],\n",
      "       [ 4, 54, 12,  2],\n",
      "       [13,  2, 54,  3],\n",
      "       [20, 12, 12, 28]]), 'loss': 0.8535082605150011}\n",
      "Theoretical max accuracy: 0.9375\n",
      "Testing subject 009 with all models...\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 0 {'acc': 0.6354166666666666, 'cm': array([[51, 19,  1,  1],\n",
      "       [ 6, 53,  2, 11],\n",
      "       [ 5, 27, 18, 22],\n",
      "       [ 0,  9,  2, 61]]), 'loss': 0.8399595684475369}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 1 {'acc': 0.6805555555555556, 'cm': array([[70,  1,  1,  0],\n",
      "       [13, 51,  6,  2],\n",
      "       [20, 22, 27,  3],\n",
      "       [ 4, 12,  8, 48]]), 'loss': 0.843417591518826}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 2 {'acc': 0.71875, 'cm': array([[65,  4,  1,  2],\n",
      "       [ 8, 48,  1, 15],\n",
      "       [ 8, 18, 27, 19],\n",
      "       [ 2,  3,  0, 67]]), 'loss': 0.6911504533555772}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 3 {'acc': 0.6770833333333334, 'cm': array([[64,  4,  3,  1],\n",
      "       [10, 44, 10,  8],\n",
      "       [ 9, 14, 28, 21],\n",
      "       [ 0,  6,  7, 59]]), 'loss': 0.7571341726515028}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 4 {'acc': 0.6979166666666666, 'cm': array([[57, 12,  3,  0],\n",
      "       [ 8, 54,  8,  2],\n",
      "       [ 3, 18, 46,  5],\n",
      "       [ 1, 20,  7, 44]]), 'loss': 0.7005608346727159}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 5 {'acc': 0.6770833333333334, 'cm': array([[58, 13,  1,  0],\n",
      "       [ 7, 48, 10,  7],\n",
      "       [ 3, 22, 30, 17],\n",
      "       [ 0, 11,  2, 59]]), 'loss': 0.8125386238098145}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 6 {'acc': 0.59375, 'cm': array([[60,  8,  0,  4],\n",
      "       [ 9, 29,  1, 33],\n",
      "       [ 9, 16, 14, 33],\n",
      "       [ 0,  3,  1, 68]]), 'loss': 0.9135962592230903}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n",
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 7 {'acc': 0.7430555555555556, 'cm': array([[63,  3,  6,  0],\n",
      "       [10, 33, 22,  7],\n",
      "       [ 4,  0, 66,  2],\n",
      "       [ 1,  6, 13, 52]]), 'loss': 0.6958628760443794}\n",
      "Code will be running on device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for model 8 {'acc': 0.7986111111111112, 'cm': array([[60, 10,  1,  1],\n",
      "       [ 8, 43, 10, 11],\n",
      "       [ 0,  8, 58,  6],\n",
      "       [ 0,  3,  0, 69]]), 'loss': 0.5056737263997396}\n",
      "Theoretical max accuracy: 0.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../centralRepo/baseModel.py:565: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return predicted, actual, torch.tensor(loss).item()/totalCount, predicted_probs\n"
     ]
    }
   ],
   "source": [
    "subs = list(range(9))\n",
    "accs = []\n",
    "all_preds = {}\n",
    "all_pred_probs = {}\n",
    "all_losses = {}\n",
    "all_test_results = {}\n",
    "all_acts = {}\n",
    "all_train_preds = {}\n",
    "all_train_pred_probs = {}\n",
    "all_train_losses = {}\n",
    "all_train_results = {}\n",
    "for test_sub in subs:\n",
    "    test_sub_str = '00' + str(test_sub + 1)\n",
    "    preds = []\n",
    "    pred_probs = []\n",
    "    train_preds = []\n",
    "    train_pred_probs = []\n",
    "    results = {}\n",
    "    train_results = {}\n",
    "    train_losses = []\n",
    "    print(\"Testing subject \" + test_sub_str + \" with all models...\")\n",
    "    for sub in subs:\n",
    "        if(sub == test_sub):\n",
    "            state_dict_path = os.path.join(ROOT_PATH, 'sub' + str(sub), 'network_state_dict.pth')\n",
    "        else:\n",
    "            state_dict_path = os.path.join(ROOT_PATH, 'sub' + str(sub), 'finetuned_sub' + str(test_sub), 'network_state_dict.pth')\n",
    "    #     print(state_dict_path)\n",
    "        netInitState = torch.load(state_dict_path)\n",
    "        net.load_state_dict(netInitState, strict=False)\n",
    "        outPathSub = None\n",
    "        model = baseModel(net=net, resultsSavePath=outPathSub, batchSize= config['batchSize'], nGPU = nGPU)\n",
    "        testResults, pred, act, pred_prob = test_model(test_sub_str, data, model, session='0')\n",
    "        train_preds.append(pred)\n",
    "        train_pred_probs.append(pred_prob)\n",
    "        train_results[sub] = testResults\n",
    "        train_losses.append(testResults['loss'])\n",
    "        \n",
    "        testResults, pred, act, pred_prob = test_model(test_sub_str, data, model)\n",
    "        preds.append(pred)\n",
    "        pred_probs.append(pred_prob)\n",
    "        results[sub] = testResults\n",
    "        print(\"Results for model\", sub, testResults)\n",
    "    \n",
    "    correct = 0\n",
    "    for i in range(len(act)):\n",
    "        for pred in preds:\n",
    "            if(pred[i] == act[i]):\n",
    "                correct += 1\n",
    "                break\n",
    "    \n",
    "    all_preds[test_sub] = preds\n",
    "    all_pred_probs[test_sub] = pred_probs\n",
    "    all_acts[test_sub] = act\n",
    "    all_test_results[test_sub] = results\n",
    "    \n",
    "    all_train_preds[test_sub] = train_preds\n",
    "    all_train_pred_probs[test_sub] = train_pred_probs\n",
    "    all_train_losses[test_sub] = train_losses\n",
    "    all_train_results[test_sub] = train_results\n",
    "    \n",
    "    acc = correct/len(act)\n",
    "    accs.append(acc)\n",
    "    print(\"Theoretical max accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9791666666666666,\n",
       " 0.8472222222222222,\n",
       " 0.9895833333333334,\n",
       " 0.9791666666666666,\n",
       " 0.9513888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.9444444444444444,\n",
       " 0.9375,\n",
       " 0.96875]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average theoretical max accuracy: 0.9429012345679012\n"
     ]
    }
   ],
   "source": [
    "avg_acc = sum(accs) / len(accs)\n",
    "print(\"Average theoretical max accuracy:\", avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8472222222222222, 0.5729166666666666, 0.9027777777777778, 0.8090277777777778, 0.7013888888888888, 0.5486111111111112, 0.8229166666666666, 0.8090277777777778, 0.7986111111111112]\n",
      "Subject specific average accuracy: 0.7569444444444444\n",
      "Subject specific median accuracy: 0.8090277777777778\n"
     ]
    }
   ],
   "source": [
    "sub_spec_accs = [all_test_results[i][i]['acc'] for i in range(9)]\n",
    "print(sub_spec_accs)\n",
    "print(\"Subject specific average accuracy:\", sum(sub_spec_accs) / len(sub_spec_accs))\n",
    "print(\"Subject specific median accuracy:\", statistics.median(sub_spec_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voted accuracy: 0.7916666666666666\n",
      "Voted accuracy: 0.5173611111111112\n",
      "Voted accuracy: 0.875\n",
      "Voted accuracy: 0.7256944444444444\n",
      "Voted accuracy: 0.6388888888888888\n",
      "Voted accuracy: 0.5243055555555556\n",
      "Voted accuracy: 0.7465277777777778\n",
      "Voted accuracy: 0.7708333333333334\n",
      "Voted accuracy: 0.7395833333333334\n",
      "Average voted accuracy: 0.7033179012345678\n",
      "Median voted accuracy: 0.7395833333333334\n"
     ]
    }
   ],
   "source": [
    "voted_accs = []\n",
    "for test_sub in subs:\n",
    "    voted_pred = []\n",
    "#     test_sub = 1\n",
    "    preds = all_preds[test_sub]\n",
    "    act = all_acts[test_sub]\n",
    "    for i in range(len(preds[0])):\n",
    "        votes = {l:0 for l in range(4)}\n",
    "        for pred in preds:\n",
    "            votes[pred[i]]+=1\n",
    "        voted_pred.append(max(votes, key=votes.get))\n",
    "\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(voted_pred, act):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(act)\n",
    "    voted_accs.append(voted_acc)\n",
    "    print(\"Voted accuracy:\", voted_acc)\n",
    "    \n",
    "avg_voted_acc = sum(voted_accs) / len(voted_accs)\n",
    "print(\"Average voted accuracy:\", avg_voted_acc)\n",
    "print(\"Median voted accuracy:\", statistics.median(voted_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft probability combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft probability combined accuracy: 0.8020833333333334\n",
      "Soft probability combined accuracy: 0.5486111111111112\n",
      "Soft probability combined accuracy: 0.8819444444444444\n",
      "Soft probability combined accuracy: 0.7569444444444444\n",
      "Soft probability combined accuracy: 0.7118055555555556\n",
      "Soft probability combined accuracy: 0.5347222222222222\n",
      "Soft probability combined accuracy: 0.7638888888888888\n",
      "Soft probability combined accuracy: 0.7743055555555556\n",
      "Soft probability combined accuracy: 0.7708333333333334\n",
      "Average combined accuracy: 0.7272376543209876\n",
      "Median combined accuracy: 0.7638888888888888\n"
     ]
    }
   ],
   "source": [
    "comb_accs = []\n",
    "for test_sub in subs:\n",
    "    pred_probs = np.array(all_pred_probs[test_sub])\n",
    "    n, h, w, c = pred_probs.shape\n",
    "    pred_probs = np.reshape(pred_probs, (n, h*w, c))\n",
    "    class_probs = np.sum(pred_probs, axis=0)\n",
    "    soft_preds = np.argmax(class_probs, axis=1)\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(soft_preds, all_acts[test_sub]):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(all_acts[test_sub])\n",
    "    comb_accs.append(voted_acc)\n",
    "    print(\"Soft probability combined accuracy:\", voted_acc)\n",
    "\n",
    "avg_comb_acc = sum(comb_accs) / len(comb_accs)\n",
    "print(\"Average combined accuracy:\", avg_comb_acc)\n",
    "print(\"Median combined accuracy:\", statistics.median(comb_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = {test_sub: {train_sub: results['cm'] for train_sub, results in test_results.items()} for test_sub, test_results in all_train_results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {test_sub: {train_sub: np.array([cm[i][i]/np.sum(cm[i,:]) for i in range(4)]) for train_sub, cm in test_results.items()} for test_sub, test_results in cms.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_sums = {test_sub: np.array([np.sum(recalls) for train_sub, recalls in test_results.items()]) for test_sub, test_results in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.        , 4.        , 3.90277778, 3.94444444, 3.95833333,\n",
       "       3.91666667, 3.97222222, 3.86111111, 4.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_sums[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 5, 3, 4, 6, 0, 1, 8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(recall_sums[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft probability combined accuracy: 0.8055555555555556\n",
      "Soft probability combined accuracy: 0.5486111111111112\n",
      "Soft probability combined accuracy: 0.8819444444444444\n",
      "Soft probability combined accuracy: 0.7569444444444444\n",
      "Soft probability combined accuracy: 0.7152777777777778\n",
      "Soft probability combined accuracy: 0.5277777777777778\n",
      "Soft probability combined accuracy: 0.7673611111111112\n",
      "Soft probability combined accuracy: 0.7743055555555556\n",
      "Soft probability combined accuracy: 0.7708333333333334\n",
      "Average combined accuracy: 0.7276234567901233\n",
      "Median combined accuracy: 0.7673611111111112\n"
     ]
    }
   ],
   "source": [
    "comb_accs = []\n",
    "for test_sub in subs:\n",
    "    pred_probs = np.array(all_pred_probs[test_sub])\n",
    "    n, h, w, c = pred_probs.shape\n",
    "    pred_probs = np.reshape(pred_probs, (n, h*w, c))\n",
    "#     print(pred_probs)\n",
    "    for i in range(len(pred_probs)):\n",
    "#         print(pred_probs[i])\n",
    "        for j in range(len(pred_probs[i])):\n",
    "            pred_probs[i][j] = np.multiply(pred_probs[i][j], metrics[test_sub][i])\n",
    "    class_probs = np.sum(pred_probs, axis=0)\n",
    "    soft_preds = np.argmax(class_probs, axis=1)\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(soft_preds, all_acts[test_sub]):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(all_acts[test_sub])\n",
    "    comb_accs.append(voted_acc)\n",
    "    print(\"Soft probability combined accuracy:\", voted_acc)\n",
    "\n",
    "avg_comb_acc = sum(comb_accs) / len(comb_accs)\n",
    "print(\"Average combined accuracy:\", avg_comb_acc)\n",
    "print(\"Median combined accuracy:\", statistics.median(comb_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voted accuracy: 0.7916666666666666\n",
      "Voted accuracy: 0.5243055555555556\n",
      "Voted accuracy: 0.8715277777777778\n",
      "Voted accuracy: 0.7291666666666666\n",
      "Voted accuracy: 0.6388888888888888\n",
      "Voted accuracy: 0.5416666666666666\n",
      "Voted accuracy: 0.7465277777777778\n",
      "Voted accuracy: 0.7673611111111112\n",
      "Voted accuracy: 0.7291666666666666\n",
      "Average voted accuracy: 0.7044753086419753\n",
      "Median voted accuracy: 0.7291666666666666\n"
     ]
    }
   ],
   "source": [
    "voted_accs = []\n",
    "for test_sub in subs:\n",
    "    voted_pred = []\n",
    "#     test_sub = 1\n",
    "    preds = all_preds[test_sub]\n",
    "    act = all_acts[test_sub]\n",
    "    for i in range(len(preds[0])):\n",
    "        votes = {l:0 for l in range(4)}\n",
    "        for j, pred in enumerate(preds):\n",
    "            votes[pred[i]]+=metrics[test_sub][j][pred[i]]\n",
    "        voted_pred.append(max(votes, key=votes.get))\n",
    "\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(voted_pred, act):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(act)\n",
    "    voted_accs.append(voted_acc)\n",
    "    print(\"Voted accuracy:\", voted_acc)\n",
    "    \n",
    "avg_voted_acc = sum(voted_accs) / len(voted_accs)\n",
    "print(\"Average voted accuracy:\", avg_voted_acc)\n",
    "print(\"Median voted accuracy:\", statistics.median(voted_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recall scaled soft probability combined accuracy: 0.8055555555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.5486111111111112\n",
      "Top recall scaled soft probability combined accuracy: 0.8819444444444444\n",
      "Top recall scaled soft probability combined accuracy: 0.75\n",
      "Top recall scaled soft probability combined accuracy: 0.6770833333333334\n",
      "Top recall scaled soft probability combined accuracy: 0.5486111111111112\n",
      "Top recall scaled soft probability combined accuracy: 0.8055555555555556\n",
      "Top recall scaled soft probability combined accuracy: 0.7916666666666666\n",
      "Top recall scaled soft probability combined accuracy: 0.7847222222222222\n",
      "Average combined accuracy: 0.7326388888888888\n",
      "Median combined accuracy: 0.7847222222222222\n"
     ]
    }
   ],
   "source": [
    "comb_accs = []\n",
    "for test_sub in subs:\n",
    "    sorted_recall_idx = np.argsort(recall_sums[test_sub])\n",
    "    # print(sorted_recall_idx)\n",
    "    # print(sorted_recall_idx[-5:])\n",
    "    pred_probs = np.array(all_pred_probs[test_sub])\n",
    "    n, h, w, c = pred_probs.shape\n",
    "    pred_probs = np.reshape(pred_probs, (n, h*w, c))\n",
    "#     print(pred_probs.shape)\n",
    "    pred_probs = np.take(pred_probs, sorted_recall_idx[-3:], 0)\n",
    "#     print(pred_probs.shape)\n",
    "    for i in range(len(pred_probs)):\n",
    "        for j in range(len(pred_probs[i])):\n",
    "            pred_probs[i][j] = np.multiply(pred_probs[i][j], metrics[test_sub][i])\n",
    "    class_probs = np.sum(pred_probs, axis=0)\n",
    "    soft_preds = np.argmax(class_probs, axis=1)\n",
    "    correct = 0\n",
    "    for pred, act_val in zip(soft_preds, all_acts[test_sub]):\n",
    "        if(pred == act_val):\n",
    "            correct += 1\n",
    "    voted_acc = correct / len(all_acts[test_sub])\n",
    "    comb_accs.append(voted_acc)\n",
    "    print(\"Top recall scaled soft probability combined accuracy:\", voted_acc)\n",
    "    \n",
    "avg_comb_acc = sum(comb_accs) / len(comb_accs)\n",
    "print(\"Average combined accuracy:\", avg_comb_acc)\n",
    "print(\"Median combined accuracy:\", statistics.median(comb_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
